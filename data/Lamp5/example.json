[
    {
      "title": "Stochastic Functions Using Sequential Logic",
      "abstract": "Stochastic computing is a novel approach to real arithmetic, offering better error tolerance and lower hardware costs over the conventional implementations. Stochastic modules are digital systems that process random bit streams representing real values in the unit interval. Stochastic modules based on finite state machines (FSMs) have been shown to realize complicated arithmetic functions much more efficiently than combinational stochastic modules. However, a general approach to synthesize FSMs for realizing arbitrary functions has been elusive. We describe a systematic procedure to design FSMs that implement arbitrary real-valued functions in the unit interval using the Taylor series approximation.",
      "id": "4020"
    },
    {
      "title": "Large Block CLOCK (LB-CLOCK): A write caching algorithm for solid state disks",
      "abstract": "Solid State Disks (SSDs) using NAND flash memory are increasingly being adopted in the high-end servers of data- centers to improve performance of the I/O-intensive applications. Compared to the traditional enterprise class hard disks, SSDs provide faster read performance, lower cooling cost, and higher power efficiency. However, write performance of a flash based SSD can be up to an order of magnitude slower than its read performance. Furthermore, frequent write operations degrade the lifetime of flash memory. A nonvolatile cache can greatly help to solve these problems. Although a RAM cache is relative high in cost, it has successfully eliminated the performance gap between fast CPU and slow magnetic disk. Similarly, a nonvolatile cache in an SSD can alleviate the disparity between the flash memory's read and write performance. A small write cache that reduces the number of flash block erase operations, can lead to substantial performance gain for write-intensive applications and can extend the overall lifetime of flash based SSDs. This paper presents a novel write caching algorithm, the Large Block CLOCK (LB-CLOCK) algorithm, which considers 'recency' and 'block space utilization' metrics to make cache management decisions. LB-CLOCK dynamically varies the priority between these two metrics to adapt to changes in workload characteristics. Our simulation based experimental results show that LB-CLOCK outperforms the best known existing flash caching algorithms for a wide range of workloads.",
      "id": "4021"
    },
    {
      "title": "High-Level Information - An Approach for Integrating Front-End and Back-End Compilers",
      "abstract": "We propose a new universal High-Level Information (HLI) format to effectively integrate front-end and back-end compilers by passing front-end information to the back-end compiler. Importing this information into an existing back- end leverages the state-of-the-art analysis and transforma- tion capabilities of existing front-end compilers to allow the back-end greater optimization potential than it has when re- lying on only locally-extracted information. A version of the HLI has been implemented in the SUIF parallelizing com- piler and the GCC back-end compiler. Experimental results with the SPEC benchmarks show that HLI can provide GCC with substantially more accurate data dependence informa- tion than it can obtain on its own. Our results show that the number of dependence edges in GCC can be reduced by an average of 48% for the integer benchmark programs and an average of 54% for the floating-point benchmark pro- grams studied, which provides greater flexibility to GCC's code scheduling pass. Even with the scheduling optimiza- tion limited to basic blocks, the use of HLI produces mod- erate speedups compared to using only GCC's dependence tests when the optimized programs are executed on MIPS R4600 and R10000 processors.",
      "id": "4022"
    },
    {
      "title": "Integrating Parallelizing Compilation Technology and Processor Architecture for Cost-Effective Concurrent multithreading",
      "abstract": "As the number of transistors on a single chip continues to grow, it is important to think beyond the traditional approaches of compiler optimization for deeper pipelines and wider instruction issue units to improve performance. This singlethreaded execution model limits these approaches to exploiting only the relatively small amount of instruction-level parallelism available in application programs. While integrating an entire multiprocessor onto a single chip is feasible, this architecture is limited to exploiting only relatively coarse-grained parallelism. We propose a concurrent multithreaded architecture, called the superthreaded architecture, as an alternative. As a hybrid of a wide-issue superscalar processor and a multiprocessor-on-a-chip, this new concurrent multithreading architecture can leverage the best of existing and future parallel hardware and compilation technologies. By combining compiler-directed thread-level speculation for control and data dependences with run-time checking of data dependences, the superthreaded architecture can exploit the multiple granularities of parallelism available in general-purpose application programs to reduce the execution time of a single program.",
      "id": "4023"
    },
    {
      "title": "Improving Energy and Performance with Spintronics Caches in Multicore Systems.",
      "abstract": "Spintronic memory (STT-MRAM) is an attractive alternative technology to CMOS since it offers higher density and virtually no leakage current. Spintronic memory continues to require higher write energy, however, presenting a challenge to memory hierarchy design when energy consumption is a concern. Various techniques for reducing write energy have been studied in the past for a single processor, typically focusing on the last-level caches while keeping the first level caches in CMOS to avoid the write latency. In this work, use of STT-MRAM for the first level caches of a multicore processor is motivated by showing that the impact on throughput due to increased write latency is offset in many cases by increased cache size due to higher density. The Parsec benchmark suite is run on a modern multicore platform simulator, comparing performance and energy consumption of the spintronic cache system to a CMOS design. A small, fully-associative level-0 cache is then introduced (on the order of 8-64 cache lines), and shown to effectively hide the STT-MRAM write latency. Performance degradation due to write latency is restored or slightly improved, while cache energy consumption is reduced by 30-50% for 12 of the 13 benchmarks.",
      "id": "4024"
    },
    {
      "title": "Increasing Instruction-Level Parallelism with Instruction Precomputation (Research Note)",
      "abstract": "Value reuse improves a processor's performance by dynamically caching the results of previous instructions and reusing those results to bypass the execution of future instructions that have the same opcode and input operands. However, continually replacing the least recently used entries could eventually fill the value reuse table with instructions that are not frequently executed. Furthermore, the complex hardware that replaces entries and updates the table may necessitate an increase in the clock period. We propose instruction precomputation to cthese issues by profiling programs to determine the opcodes and input operands that have the highest frequencies of execution. These instructions then are loaded into the precomputation table before the program executes. During program execution, the precomputation table is used in the same way as the value reuse table is, with the exception that the precomputation table does not dynamically replace any entries. For a 2K-entry pre-computation table implemented on a 4-way issue machine, this approach produced an average speedup of 11.0%. By comparison, a 2K-entry value reuse table produced an average speedup of 6.7%. Instruction precomputation outperforms value reuse, especially for smaller tables, with the same number of table entries while using less area and having a lower access time.",
      "id": "4025"
    },
    {
      "title": "Cross-layer speculative architecture for end systems and gateways in computer networks with lossy links",
      "abstract": "The throughput degradation of Transport Control Protocol (TCP)/Internet Protocol (IP) networks over lossy links due to the coexistence of congestion losses and link corruption losses is very similar to the degradation of processor performance (i.e., cycle per instruction) due to control hazards in computer design. First, two types of loss events in networks with lossy links are analogous to two possibilities of a branching result in computers (taken vs. not taken). Secondly, both problems result in performance degradations in their applications, i.e., penalties (in clock cycles) in a processor, and throughput degradation (in bits per second) in a TCP/IP network. This has motivated us to apply speculative techniques (i.e., speculating on the outcome of branch predictions), used to overcome control dependencies in a processor, for throughput improvements when lossy links are involved in TCP/IP connections. The objective of this paper is to propose a cross-layer network architecture to improve the network throughput over lossy links. The system consists of protocol-level speculation based algorithms at transport layer, and protocol enhancements at middleware and network layers that provide control and performance parameters to transport layer functions. Simulation results show that, compared with prior research, our proposed system is effective in improving network throughput over lossy links, capable of handling incorrect speculations, fair for other competing flows, backward compatible with legacy networks, and relatively easy to implement.",
      "id": "4026"
    },
    {
      "title": "Self-tuning Speculation for Maintaining the Consistency of Client-Cached Data",
      "abstract": "This paper presents a new protocol, Self-tuning ActiveData-aware Cache Consistency (SADCC), which employsparallel communication and self-tuning speculation toimprove the performance of data-shipping database systems.Using parallel communication with simultaneous client-serverand client-client communication, SADCC reduces thenetwork latency for detecting data conflicts by 50%, whileincreasing message volume overhead by only about 4.8%. Bybeing aware of the global states of cached data, clients self-tunebetween optimistic and pessimistic consistency control.The abort rate is reduced by statistically quantifying thespeculation cost. We compare SADCC with the leadingcache consistency algorithms, Active Data-aware CacheConsistency (ADCC) and Asynchronous Avoidance-basedCache Consistency (AACC), in a page server DBMSarchitecture with page-level consistency. The experimentsshow that, in a non-contention environment, both SADCCand ADCC display a slight reduction (an average of 2.3%)in performance compared to AACC with a high-speednetwork environment. With high contention, however,SADCC has an average of 14% higher throughput thanAACC and 6% higher throughput than ADCC.",
      "id": "4027"
    },
    {
      "title": "The Applicability of Adaptive Control Theory to QoS Design: Limitations and Solutions",
      "abstract": "Due to the increasing complexity, the behavior of large-scale distributed systems becomes difficult to predict. The ability of on-line identification and autotuning of adaptive control systems has made the adaptive control theoretical design an attractive approach for quality of service (QoS) guarantee. However, there is an inherent constraint in adaptive control systems, i.e. a conflict between asymptotically good control and asymptotically good parameter estimates. This paper addresses these limitations via sensitivity analysis. The simulation study demonstrates that the adaptive control theoretical design depends on the excitation signal, environment uncertainty, and a priori knowledge on the system. In addition, this paper proposes an adaptive dual control framework for mitigating these constraints in QoS design. By incorporating the existing uncertainty of the on-line prediction into the control strategy, the dual adaptive control framework optimizes the tradeoff between the control goal and the uncertainty.",
      "id": "4028"
    },
    {
      "title": "Exploiting the Prefetching Effect Provided by Executing Mispredicted Load Instructions",
      "abstract": "As the degree of instruction-level parallelism in superscalar architectures increases, the gap between processor and memory performance continues to grow requiring more aggressive techniques to increase the performance of the memory system. We propose a new technique, which is based on the wrong-path execution of loads far beyond instruction fetch-limiting conditional branches, to exploit more instruction-level parallelism by reducing the impact of memory delays. We examine the effects of the execution of loads down the wrong branch path on the performance of an aggressive issue processor. We find that, by continuing to execute the loads issued in the mispredicted path, even after the branch is resolved, we can actually reduce the cache misses observed on the correctly executed path. This wrong-path execution of loads can result in a speedup of up to 5% due to an indirect prefetching effect that brings data or instruction blocks into the cache for instructions subsequently issued on the correctly predicted path. However, it also can increase the amount of memory traffic and can pollute the cache. We propose the Wrong Path Cache (WPC) to eliminate the cache pollution caused by the execution of loads down mispredicted branch paths. For the configurations tested, fetching the results of wrong path loads into a fully associative 8-entry WPC can result in a 12% to 39% reduction in L1 data cache misses and in a speedup of up to 37%, with an average speedup of 9%, over the baseline processor.",
      "id": "4029"
    },
    {
      "title": "Dynamic scheduling strategies for shared-memory multiprocessors",
      "abstract": "Efficiently scheduling parallel tasks on to the processors of a shared-memory multiprocessor is critical to achieving high performance. Given perfect information at compile-time, a static scheduling strategy can produce an assignment of tasks to processors that ideally balances the load among the processors while minimizing the run-time scheduling overhead and the average memory referencing delay. Since perfect information is seldom available, however, dynamic scheduling strategies distribute the task assignment function to the processors by having idle processors allocate work to themselves from a shared queue. While this approach can improve the load balancing compared to static scheduling, the time required to access the shared work queue adds directly to the overall execution time. To overlap the time required to dynamically schedule tasks with the execution of the tasks, we examine a class of self-adjusting dynamic scheduling (SADS) algorithms that centralizes the assignment of tasks to processors. These algorithms dedicate a single processor of the multiprocessor to perform a novel on-line branch-and-bound technique that dynamically computes partial schedules based on the loads of the other processors and the memory locality (affinity) of the tasks and the processors. Our simulation results show that this centralized scheduling outperforms self-scheduling algorithms even when using only a small number of processors.",
      "id": "40210"
    },
    {
      "title": "SCRAP: A Statistical Approach for Creating a Database Query Workload Based on Performance Bottlenecks",
      "abstract": "With the tremendous growth in stored data, the role of database systems has become more significant than ever before. Standard query workloads, such as the TPC-C and TPC-H benchmark suites, are used to evaluate and tune the functionality and performance of database systems. Running and configuring benchmarks is a time consuming task. It requires substantial statistical expertise due to the enormous data size and large number of queries in the workload. Subsetting can be used to reduce the number of queries in a workload. An existing workload subsetting technique selected queries based on similarities of the ranks of the queries for low-level characteristics, such as cache miss rates, or based on the execution time required in different computer systems. However, many low-level characteristics are correlated, produce similar behaviors. Also, raw execution time as a metric is too diffuse to capture important performance bottlenecks. Our goal is to select a subset of queries that can reproduce the same bottlenecks in the system as the original workload. In this paper, we propose a statistical approach for creating a database query workload based on performance bottlenecks (SCRAP). Our methodology takes a query workload and a set of system configuration parameters as inputs, and selects a subset of the queries from the workload based on the similarity of performance bottlenecks. Experimental results using the TPC-H benchmark and the PostgreSQL database system, show that the reduced workload and the original workload produce similar performance bottlenecks, and the subset accurately estimates the total execution time.",
      "id": "40211"
    },
    {
      "title": "Trends in Shared Memory Multiprocessing",
      "abstract": "Shared memory multiprocessing is recognized by industry as a key technology for domains such as decision support systems and multimedia processing. Like uniprocessors, shared memory multiprocessors are often built from high-performance microprocessors, so there is a clear transition path from uniprocessor to multiprocessor program implementations. The challenge lies in making this transition as smooth as possible, both in performance and the programming required to achieve it. The first step is to examine the current use of shared memory multiprocessing and arrive at intelligent projections of future use. The second step is to begin filling gaps in programming models and architectures for shared memory multiprocessing. The third step-possibly taken concurrently with the second-is to make the development of parallel software more feasible. Perhaps the greatest challenge is to develop new techniques in the face of a moving hardware target. The community must somehow improve the software and keep pace with constant increases in integration level, on-chip parallelism, and memory hierarchy complexity.",
      "id": "40212"
    },
    {
      "title": "Utilizing Heterogeneous Networks in Distributed Parallel Computing Systems",
      "abstract": "Heterogeneity is becoming quite common in distributed parallel computing systems, both in processor architectures and in communication networks. Different types of networks have different performance characteristics, while different types of messages may have different communication requirements. In this work, we analyze two techniques for exploiting these heterogeneous characteristics and requirements to reduce the communication overhead of parallel application programs executed on distributed computing systems. The performance based path selection (PBPS) technique selects the best (lowest latency) network among several for each individual message, while the second technique aggregates multiple networks into a single virtual network. We present a general approach for applying and evaluating these techniques to a distributed computing system with multiple interprocessor communication networks. We also generate performance curves for a cluster of IBM workstations interconnected with Ethernet, ATM, and Fibre Channel networks. As we show with several of the NAS benchmarks, these curves can be used to estimate the potential improvement in communication performance that can be obtained with these techniques, given some simple communication characteristics of an application program.",
      "id": "40213"
    },
    {
      "title": "Characterization of Communication Patterns in Message-Passing Parallel Scientific Application Programs",
      "abstract": "This paper examines the communication patterns of parallel scientific programs, including some of the NAS benchmarks and the\n Miami Isopycnic Coordinate Ocean Model (MICOM), that use explicit message-passing. Communication locality, including communication event locality, message destination locality, and message size locality, is proposed and studied\n in addition to the widely accepted metrics of message size, destination, and generation distributions. We find that the locality\n metrics are relatively insensitive to system and problem size variations making them robust metrics for characterizing the\n communication patterns of parallel applications. We observe that the communication patterns of the benchmark programs are\n consistent with those of the actual application. The results of this study will be useful for understanding parallel applications'\n communication behavior and for designing more realistic synthetic benchmarks.\n ",
      "id": "40214"
    },
    {
      "title": "Dynamic code region (DCR) based program phase tracking and prediction for dynamic optimizations",
      "abstract": "Detecting and predicting a program's execution phases are crucial to dynamic optimizations and dynamically adaptable systems. This paper shows that a phase can be associated with dynamic code regions embedded in loops and procedures which are primary targets of compiler optimizations. This paper proposes a new phase tracking hardware, especially for dynamic optimizations, that effectively identifies and accurately predicts program phases by exploiting program control flow information. Our proposed phase tracking hardware uses a simple stack and a phase signature table to track the change of phase signature between dynamic code regions. Several design parameters of our proposed phase tracking hardware are evaluated on 10 SPEC CPU2000 benchmarks. Our proposed phase tracking hardware effectively identifies a phase at a given granularity. It correctly predicts the next program phase for 84.9% of times with a comparable small performance variance within the same phase. A longer phase length and higher phase prediction accuracy together with a reasonably small performance variance are essential to build more efficient dynamic profiling and optimization systems.",
      "id": "40215"
    },
    {
      "title": "Loop-Level Process Control: An Effective Processor Allocation Policy for Multiprogrammed Shared-Memory Multiprocessors",
      "abstract": "Processor time-sharing is the most common way to increase the overall system utilization for shared-memory multiprocessor systems. However, the performance of individual applications might be sacrificed due to the high overhead of context switching, due to the processing power wasted by busy-waiting synchronization and locking operations, and due to poor cache memory utilization. In this paper, we propose a simple and effective processor allocation scheme, called Loop-Level Process Control (LLPC), for multiprogrammed multiprocessors. At the beginning of each parallel section of each application program, LLPC uses the current system load to determine an upper limit on the number of processes the application can create for that parallel section. Preliminary simulation results using the Perfect Club Fortran benchmarks show that this loop-level process control scheme can produce a high system utilization while maintaining high performance for the individual applications. Another advantage of this strategy is that it is transparent to the programmer and does not require any modifications to the operating system. Consequently, the application can remain portable and compatible.",
      "id": "40216"
    },
    {
      "title": "Shared-memory multiprocessing: Current state and future directions",
      "abstract": "Progress in shared-memory multiprocessing research over the last several decades has led to its industrial recognition as a key technology for a variety of performance-demanding application domains. In this chapter, we summarize the current state of this technology including system architectures, programming interfaces, and compiler and tool technology offered to the application writer. We the identify important issues for future research in relation to technology and application trends. We particularly focus on research directions in machine architectures, programming interfaces, and parallelization methodologies.",
      "id": "40217"
    },
    {
      "title": "Using Stochastic Computing to Reduce the Hardware Requirements for a Restricted Boltzmann Machine Classifier.",
      "abstract": "Artificial neural networks are powerful computational systems with interconnected neurons. Generally, these networks have a very large number of computation nodes which forces the designer to use software-based implementations. However, the software based implementations are offline and not suitable for portable or real-time applications. Experiments show that compared with the software based implementations, FPGA-based systems can greatly speed up the computation time, making them suitable for real-time situations and portable applications. However, the FPGA implementation of neural networks with a large number of nodes is still a challenging task.\n\nIn this paper, we exploit stochastic bit streams in the Restricted Boltzmann Machine (RBM) to implement the classification of the RBM handwritten digit recognition application completely on an FPGA. We use finite state machine-based (FSM) stochastic circuits to implement the required sigmoid function and use the novel stochastic computing approach to perform all large matrix multiplications. Experimental results show that the proposed stochastic architecture has much more potential for tolerating faults while requiring much less hardware compared to the currently un-implementable deterministic binary approach when the RBM consists of a large number of neurons. Exploiting the features of stochastic circuits, our implementation achieves much better performance than a software-based approach.\n\n",
      "id": "40218"
    },
    {
      "title": "Towards Theoretical Cost Limit of Stochastic Number Generators for Stochastic Computing",
      "abstract": "Stochastic number generator (SNG) is one important component of stochastic computing (SC). An SNG usually consists of a random number source (RNS) and a probability conversion circuit (PCC). The SNGs occupy a large portion of the total area and power of a stochastic circuit. Thus, it is critical to lower the area and power of the SNGs. The existing methods only focused on simplifying the RNSs inside the SNGs, such as sharing the RNSs and using emerging devices. However, how to reduce the area and power of PCCs is never studied. In this work, we explore this problem and propose a solution that can effectively reduce the area and power of PCCs. We also study the theoretical limit on the cost of SNG and find that our proposed design approaches the limit. The experimental results show that our design can gain up to 2\u00d7 improvement in power-delay product over the traditional SNGs.",
      "id": "40219"
    },
    {
      "title": "Implementing A Dynamic Processor Allocation Policy For Multiprogrammed Parallel Applications In The Solaris (Tm) Operating System",
      "abstract": "Parallel applications typically do not perform well in a multiprogrammed environment that uses time-sharing to allocate processor resources to the applications' parallel threads. Co-scheduling related parallel threads, or statically partitioning the system, often can reduce the applications' execution times, but at the expense of reducing the overall system utilization. To address this problem, there has been increasing interest in dynamically allocating processors to applications based on their resource demands and the dynamically varying system load. The Loop-Level Process Control (LLPC) policy (Yue K, Lilja D. Efficient execution of parallel applications in multiprogrammed multiprocessor systems. 10th International Parallel Processing Symposium, 1996; 448-456) dynamically adjusts the number of threads an application is allowed to execute based on the application's available parallelism and the overall system load. This study demonstrates the feasibility of incorporating the LLPC strategy into an existing commercial operating system and parallelizing compiler and provides further evidence of the performance improvement that is possible using this dynamic allocation strategy. In this implementation, applications are automatically parallelized and enhanced with the appropriate LLPC hooks so that each application interacts with the modified version of the Solaris operating system. The parallelism of the applications are then dynamically adjusted automatically when they are executed in a multiprogrammed environment so that all applications obtain a fair share of the total processing resources. Copyright (C) 2001 John Wiley & Sons, Ltd.",
      "id": "40220"
    },
    {
      "title": "Efficient and Fast Approximate Consensus with Epidemic Failure Detection at Extreme Scale",
      "abstract": "This paper proposes a memory efficient failure detection and consensus algorithm, for fail-stop type process failures, based on epidemic protocols. It is suitable for extreme scale systems with reliable networks (no message loss) and high failure frequency. Communication time dominates the execution time at scale. The redundant failure detections and non-uniform information dissemination speed of epidemic algorithms make approximate epidemic-based consensus detection a useful way to trade communication overhead for accuracy. An approximate technique to the consensus detection is also proposed in this paper for faster consensus detection. Results show that the algorithm detects consensus correctly on failed processes with logarithmic scalability. The algorithm is tolerant to process failures both before and during the execution and the number of failures (occurring both before and during execution) have virtually no effect on the consensus detection time at scale. Comparison with similar deterministic consensus detection technique shows that the algorithm detects consensus at the same time with high probability. Further, benefits of the proposed approximate technique increase as system size increases. Compared to the non-approximate version, for a system size of 218 processes, the communication saved is 34% with accuracy loss of the order of 10^-4 in consensus detection.",
      "id": "40221"
    },
    {
      "title": "Temperature-aware floorplanning of microarchitecture blocks with IPC-power dependence modeling and transient analysis",
      "abstract": "Operating temperatures have become an important concern in high performance microprocessors. Floorplanning or block-level placement offers excellent potential for thermal optimization through better heat spreading between the blocks, but these optimizations can also impact the throughput of a microarchitecture, measured in terms of the number of instructions per cycle (IPC). In nanometer technologies, global buses can have multicycle delays that depend on the positions of the blocks, and it is important for a floorplanner to be microarchitecturally-aware to be sure that thermal and IPC considerations are appropriately balanced. This paper proposes a methodology for thermally-aware microarchitecture floorplanning. The approach models the interactions between the IPC and the temperature distribution, and incorporates both factors in the floorplanning cost function. Our approach uses transient modeling and optimizes both the peak and the average temperatures, and employs a design of experiments (DOE) based strategy, which effectively captures the huge exponential search space with a small number of cycle-accurate simulations. A comparison with a technique based on previous work indicates that the proposed approach results in good reductions both in the average and the peak temperatures for a range of SPEC benchmarks.",
      "id": "40222"
    },
    {
      "title": "Exploiting the parallelism available in loops",
      "abstract": "Because a loop's body often executes many times, loops provide a rich opportunity for exploiting parallelism. This article explains scheduling techniques and compares results on different architectures. Since parallel architectures differ in synchronization overhead, instruction scheduling constraints, memory latencies, and implementation details, determining the best approach for exploiting parallelism can be difficult. To indicate their performance potential, this article surveys several architectures and compilation techniques using a common notation and consistent terminology. First we develop the critical dependence ratio to determine a loop's maximum possible parallelism, given infinite hardware. Then we look at specific architectures and techniques. Loops can provide a large portion of the parallelism available in an application program, since the iterations of a loop may be executed many times. To exploit this parallelism, however, one must look beyond a single basic block or a single iteration for independent operations. The choice of technique depends on the underlying architecture of the parallel machine and the characteristics of each individual loop.<>",
      "id": "40223"
    },
    {
      "title": "Challenges in Computer Architecture Evaluation",
      "abstract": "Reasoning about today's tremendously complex computer systems is difficult and developing them is expensive. Detailed software simulations are thus essential for evaluating computer architecture ideas. Industry uses simulation extensively during processor and system design as the easiest and least expensive way to explore design options.Unfortunately, constructing accurate models of modern computer systems is becoming harder and more time-consuming, while the effort required to develop high-fidelity simulation tools typically yields few academic rewards. Without funding and promising prospects for academic recognition, research and development in these areas will likely languish.",
      "id": "40224"
    },
    {
      "title": "Exploring subsets of standard cell libraries to exploit natural fault masking capabilities for reliable logic",
      "abstract": "Deep submicron technology is expected to be plagued by many reliability issues including soft errors in logic. To address this, we demonstrate how exploiting the natural fault masking characteristics of logical functions can be achieved by exploring the design space for selecting subsets of cells from within a cell library prior to synthesis. Subset selection alone is shown to improve the reliability of combinational logic circuits by more than 35%. We compare how subset libraries effect the trade-offs between reliability, area, power, and performance. Further, we show that added benefits of reduced cell library size can benefit the design.",
      "id": "40225"
    },
    {
      "title": "Statistically translating low-level error probabilities to increase the accuracy and efficiency of reliability simulations in hardware description languages",
      "abstract": "Radiation induced single-event upsets are becoming an increasing issue for designers due to the impact on overall design reliability. This paper presents a method for translating probabilistic information from lower levels in the design hierarchy into efficient, fast, and useful tools at higher levels. This method allows designers to incorporate soft error reliability analysis into the verification process at greatly reduced simulation expense with high accuracy. We also include metrics to estimate the error in the method. Results from both abstracted verification simulations and Verilog soft error simulations are presented. Our method bridges a gap between low level reliability measurements and high level reliability simulations.",
      "id": "40226"
    },
    {
      "title": "An adaptive dual control framework for QoS design",
      "abstract": "The widespread deployment of the advanced computer technology in business and industries has demanded the high standard on quality of service (QoS). For example, many Internet applications, i.e. online trading, e-commerce, and real-time databases, etc., execute in an unpredictable general-purpose environment but require performance guarantees. Failure to meet performance specifications may result in losing business or liability violations. As systems become distributed and complex, it has become a challenge for QoS design. The ability of on-line identification and auto-tuning of adaptive control systems has made the adaptive control theoretical design an attractive approach for QoS design. However, there is an inherent constraint in adaptive control systems, i.e. a conflict between asymptotically good control and asymptotically good on-line identification. This paper first identifies and analyzes the limitations of adaptive control for network QoS by extensive simulation studies. Secondly, as an approach to mitigate the limitations, we propose an adaptive dual control framework. By incorporating the existing uncertainty of on-line prediction into the control strategy and accelerating the parameter estimation process, the adaptive dual control framework optimizes the tradeoff between the control goal and the uncertainty, and demonstrates robust and cautious behavior. The experimental study shows that the adaptive dual control framework mitigate the limitations of the conventional adaptive control framework. Compared with the conventional adaptive control framework under the medium uncertainty, the adaptive dual control framework reduces the deviation from the desired hit-rate ratio from 40% to 13%.",
      "id": "40227"
    },
    {
      "title": "A multiprocessor architecture combining fine-grained and coarse-grained parallelism strategies",
      "abstract": "A wide variety of computer architectures have been proposed that attempt to exploit parallelism at different granularities. For example, pipelined processors and multiple instruction issue processors exploit the fine-grained parallelism available at the machine instruction level, while shared memory multiprocessors exploit the coarse-grained parallelism available at the loop level. Using a register-transfer level simulation methodology, this paper examines the performance of a multiprocessor architecture that combines both coarse-grained and fine-grained parallelism strategies to minimize the execution time of a single application program. These simulations indicate that the best system performance is obtained by using a mix of fine-grained and coarse-grained parallelism in which any number of processors can be used, but each processor should be pipelined to a degree of 2 to 4, or each should be capable of issuing from 2 to 4 instructions per cycle. These results suggest that current high-performance microprocessors, which typically can have 2 to 4 instructions simultaneously executing, may provide excellent components with which to construct a multiprocessor system.",
      "id": "40228"
    },
    {
      "title": "So Many States, So Little Time: Verifying Memory Coherence in the Cray X1",
      "abstract": "This paper investigates a complexity-effective technique for verifying a highly distributed directory-based cache coherence protocol. We develop a novel approach called \"witness strings\" that combines both formal and informal verification methods to expose design errors within the cache coherence protocol and its Verilog implementation. In this approach a formal execution trace is extracted during model checking of the architectural model and re-encoded to provide the input stimulus for a logic simulation of the corresponding Verilog implementation. This approach brings confidence to system architects that the logic implementation of the coherence protocol conforms to the architectural model. The feasibility of this approach is demonstrated by using it to verify the cache coherence protocol of the Cray X1. Using this approach we uncovered three architectural protocol errors and exposed several implementation errors by replaying the witness strings on the Verilog implementation.",
      "id": "40229"
    },
    {
      "title": "Speed versus Accuracy Trade-Offs in Microarchitectural Simulations",
      "abstract": "Due to the long simulation time of the reference input set, computer architects often use reduced time simulation techniques to shorten the simulation time. However, what has not yet been thoroughly evaluated is the accuracy of these techniques relative to the reference input set and with respect to each other. To rectify this deficiency, this paper uses three methods to characterize reduced input set, truncated execution, and sampling-based simulation techniques while also examining their speed vs. accuracy trade-off and configuration dependence. Our results show that the three sampling-based techniques, SimPoint, SMARTS, and random sampling, have the best accuracy, the best speed vs. accuracy trade-off, and the least configuration dependence. On the other hand, the reduced input set and truncated execution simulation techniques had generally poor accuracy, were not significantly faster than the sampling-based techniques, and were severely configuration dependent. The final contribution of this paper is a decision tree which can help architects choose the most appropriate technique for their simulations.",
      "id": "40230"
    },
    {
      "title": "Performing bitwise logic operations in cache using spintronics-based magnetic tunnel junctions",
      "abstract": "Recent exciting developments in the emerging field of spintronics have enabled rapid advances in spintronic devices such as magnetic tunnel junctions (MTJs). While MTJs are being primarily used as the basic devices in non-volatile memory, they have also been shown to accomplish primitive logic functions. However, the spintronic nature of the logic operation makes it challenging to accomplish tasks such as cascading of logic gates, operations on multiple outputs, and various combinations of these. In order to enable these primary functions, we propose the idea of adding interconnections between MTJ devices in a spintronic memory array. With this added connectivity, we show that the memory array gains the ability to perform bitwise logic operations on the data stored within it without intermediate computing circuits. We demonstrate that the basic logic operations of NAND, AND, OR and XOR operations can be performed in the memory array using the memory devices themselves. We describe the algorithms for performing the logic operations in memory and introduce the notion of a 'footprint' to compare the complexities of the operations in terms of their memory usage, data requirements and time steps. Taking into account the minimum interconnection requirements of these logic functions, we propose the design of a general spintronic logic-in-cache block and demonstrate the ADD function with it.",
      "id": "40231"
    },
    {
      "title": "Comparing processor allocation strategies in multiprogrammed shared-memory multiprocessors",
      "abstract": "Small-scale shared-memory multiprocessors are commonly used in a workgroup environment where multiple applications, both parallel and sequential, are executed concurrently while sharing the processors and other system resources. To utilize the processors efficiently, an effective allocation strategy is required. In this paper, we use performance data obtained from an SGI multiprocessor to evaluate several processor allocation strategies when running two parallel programs simultaneously. We examine gang scheduling (coscheduling), static space-sharing (space partitioning), and a dynamic allocation scheme called loop-level process control (LLPC) with three different dynamic allocation heuristics. We use regression analysis to quantify the measured data and thereby explore the relationship between the degree of parallelism of the application, specific system parameters (such as the size of the system), the processor allocation strategy, and the resulting performance. This study shows that dynamically partitioning the system using LLPC or similar heuristics provides better performance for applications with a high degree of parallelism than either gang scheduling or static space-sharing.",
      "id": "40232"
    },
    {
      "title": "Performance-based path determination for interprocessor communication in distributed computing systems",
      "abstract": "The different types of messages used by a parallel application program executing in a distributed computing system can each have unique characteristics so that no single communication network can produce the lowest latency for all messages. For instance, short control messages may be sent with the lowest overhead on one type of network, such as Ethernet, while bulk data transfers may be better suited to a different type of network, such as Fibre Channel or HIPPI. This work investigates how to exploit multiple heterogeneous communication networks that interconnect the same set of processing nodes using a set of techniques we call performance-based path determination (PBPD). The performance-based path selection (PBPS) technique selects the best (lowest latency) network among several for each individual message to reduce the communication overhead of parallel programs. The performance-based path aggregation (PBPA) technique, on the other hand, aggregates multiple networks into a single virtual network to increase the available bandwidth. We test the PBPD techniques on a cluster of SGI multiprocessors interconnected with Ethernet, Fibre Channel, and HiPPI networks using a custom communication library built on top of the TCP/IP protocol layers. We find that PBPS can reduce communication overhead in applications compared to using either network alone, while aggregating networks into a single virtual network can reduce communication latency for bandwidth-limited applications. The performance of the PBPD techniques depends on the mix of message sizes in the application program and the relative overheads of the networks, as demonstrated in our analytical models",
      "id": "40233"
    },
    {
      "title": "Partitioning Tasks Between A Pair Of Interconnected Heterogeneous Processors - A Case-Study",
      "abstract": "With the variety of computer architectures available today, it is often difficult to determine which particular type of architecture will provide the best performance on a given application program, In fact, one type of architecture may be well suited to executing one section of a program while another architecture may be better suited to executing another section of the same program, One potentially promising approach for exploiting the best features of different computer architectures is to partition an application program to simultaneously execute on two or more types of machines interconnected with a high-speed communication network, A fundamental difficulty with this heterogeneous computing, however, is the problem of determining how to partition the application program across the interconnected machines, The goal of this paper is to show how a programmer or a compiler can use a model of a heterogeneous system to determine the machine on which each subtask should be executed. This technique is illustrated with a simple model that relates the relative performance of two heterogeneous machines to the communication time required to transfer partial results across their interconnection network, Experiments with a Connection Machine CM-200 demonstrate how to apply this model to partition two different application programs across the sequential front-end processor and the parallel back-end array.",
      "id": "40234"
    },
    {
      "title": "MEMESTAR: A Simulation Framework for Reliability Evaluation over Multiple Environments",
      "abstract": "The paper presents a methodology for the simulation of soft errors targeting future nano-technological devices. This approach efficiently scales the failure rate of individual devices according to cell area and considers the effect of multiple faults within a circuit. Furthermore this methodology measures circuit operation over a range of environments and consequently provides a means of targeting designs to the expected operating environment rather than worst case. The authors demonstrate the effect area has on circuit reliability and fault tolerance",
      "id": "40235"
    },
    {
      "title": "Education at a distance: a report from the front",
      "abstract": " A course on computer systems performanceanalysis has been adapted for several different distance educationdelivery options, including an interactive televisionsystem, face-to-face presentation at a satellite campus, anddelivery over the Internet to independent study students.Of the 114 students who have enrolled in this graduate-levelcourse in the past three years, half have been nontraditionalstudents who never set foot on campus. While the studentswho enroll through the interactive... ",
      "id": "40236"
    },
    {
      "title": "A balanced approach to high-level verification: performance trade-offs in verifying large-scale multiprocessors",
      "abstract": "A single node of a modern scalable multiprocessor consists of several ASICs comprising tens of millions of gates. This level of integration and complexity imposes an enormous onus on the verification process. A variety of tools, ranging from discrete-event logic simulation to formal model checking, can be used to attack this problem. Unfortunately, conventional simulation techniques, with their primitive interface to the hardware (i.e. test vectors), are inadequate tools for reasoning about the correctness of complex architectural features, such as cache coherence protocols and memory consistency models. Similarly, model checkers offer very limited utility on such large designs. We have previously proposed [1] a novel verification framework, called Raven that addresses many of these challenges. In this paper, we examine the performance implications of verifying systems at higher levels of abstraction. A detailed performance analysis is conducted to compare this higher-level approach against an equivalent Verilog test bench. We establish lower and upper bounds on the performance of the Raven environment executing on a single-processor, on a set of distributed processors, and on a shared-memory multiprocessor.",
      "id": "40237"
    },
    {
      "title": "The Potential of Compile-Time Analysis to Adapt the Cache Coherence Enforcement Strategy to the Data Sharing Characteristics",
      "abstract": "Cache coherence schemes that dynamically adapt to memory referencing patterns have been proposed to improve coherence enforcement in shared-memory multiprocessors. By using only run-time information, however, these existing schemes are incapable of looking ahead in the memory referencing stream. We present a combined hardware-software strategy that uses the predictive capability of the compiler to select updating or invalidating for each write reference. To determine the potential performance improvement that can be achieved with this optimization, three different levels of compiler capabilities are examined. Simulations using memory traces show that with an ideal compiler, this optimization can potentially reduce the miss ratio by 0.4% to 15% compared to an invalidating-only scheme, while reducing the generated network traffic by 13% to 94 % compared to an updating-only scheme. In addition, this optimization can potentially reduce the miss ratio by up to 13%, while reducing the generated network traffic by up to 92%, compared to a dynamic adaptive scheme. Furthermore, performance can be potentially improved even with a compiler capable of performing only imprecise array subscript analysis and no interprocedural analysis.Index Terms\u9a74Compiler optimization, update, invalidate, directory, cache coherence, shared-memory, multiprocessor.",
      "id": "40238"
    },
    {
      "title": "Using stochastic computing to implement digital image processing algorithms",
      "abstract": "As device scaling continues to nanoscale dimensions, circuit reliability will continue to become an ever greater problem. Stochastic computing, which performs computing with random bits (stochastic bits streams), can be used to enable reliable computation using those unreliable devices. However, one of the major issues of stochastic computing is that applications implemented with this technique are limited by the available computational elements. In this paper, first we will introduce and prove a stochastic absolute value function. Second, we will demonstrate a mathematical analysis of a stochastic tanh function, which is a key component used in a stochastic comparator. Third, we will present a quantitative analysis of a one-parameter linear gain function, and propose a new two-parameter version. The validity of the present stochastic computational elements is demonstrated through four basic digital image processing algorithms: edge detection, frame difference based image segmentation, median filter based noise reduction, and image contrast stretching. Our experimental results show that stochastic implementations tolerate more noise and consume less hardware than their conventional counterparts.",
      "id": "40239"
    },
    {
      "title": "Techniques for obtaining high performance in Java programs",
      "abstract": "This survey describes research directions in techniques to improve the performance of programs written in the Java programming language. The standard technique for Java execution is interpretation, which provides for extensive portability of programs. A Java interpreter dynamically executes Java bytecodes, which comprise the instruction set of the Java Virtual Machine (JVM). Execution time performance of Java programs can be improved through compilation, possibly at the expense of portability. Various types of Java compilers have been proposed, including Just-In-Time (JIT) compilers that compile bytecode into native processor instructions on the fly; direct compilers that directly translate the Java source code into the target processor's native language; and bytecode-to-source translators that generate either native code or an intermediate language, such as C, from the bytecodes. Additional techniques, including bytecode optimization, dynamic compilation, and executing Java programs in parallel, attempt to improve Java run-time performance while maintaining Java's portability. Another alternative for executing Java programs is a Java processor that implements the JVM directly in hardware. In this survey, we discuss the basis features, and the advantages and disadvantages, of the various Java execution techniques. We also discuss the various Java benchmarks that are being used by the Java community for performance evaluation of the different techniques. Finally, we conclude with a comparison of the performance of the alternative Java execution techniques based on reported results.",
      "id": "40240"
    },
    {
      "title": "Guiding circuit level fault-tolerance design with statistical methods",
      "abstract": "In the last decade, the focus of fault-tolerance methods has tended towards circuit level modifications, such as transistor resizing, and away from expensive system level redundancy approaches. We present the results from a screening experiment to identify significant parameters in circuit level soft error simulations to guide such approaches to fault-tolerance. This approach allows us to assess which parameters will have the most significance for reducing soft error rates and the impact that process variation will have on the accuracy of soft error rate estimates. We identify supply voltage and transistor type as being the most significant parameters affecting soft errors in logic cells across several technology scales. Additionally, we provide a ranking of more than a dozen parameters, across four technology scales, based on the significance of their impact on soft error rates.",
      "id": "40241"
    },
    {
      "title": "Reducing the Branch Penalty in Pipelined Processors",
      "abstract": "A probabilistic model is developed to quantify the performance effects of the branch penalty in a typical pipeline. The branch penalty is analyzed as a function of the relative number of branch instructions executed and the probability that a branch is taken. The resulting model shows the fraction of maximum performance achievable under the given conditions. Techniques to reduce the branch penalty include static and dynamic branch prediction, the branch target buffer, the delayed branch, branch bypassing and multiple prefetching, branch folding, resolution of branch decision early in the pipeline, using multiple independent instruction streams in a shared pipeline, and the prepare-to-branch instruction.",
      "id": "40242"
    },
    {
      "title": "Improving Computer Architecture Simulation Methodology by Adding Statistical Rigor",
      "abstract": "Due to cost, time, and flexibility constraints, computer architects use simulators to explore the design space when developing new processors and to evaluate the performance of potential enhancements. However, despite this dependence on simulators, statistically rigorous simulation methodologies are typically not used in computer architecture research. A formal methodology can provide a sound basis for drawing conclusions gathered from simulation results by adding statistical rigor and, consequently, can increase the architect's confidence in the simulation results. This paper demonstrates the application of a rigorous statistical technique to the setup and analysis phases of the simulation process. Specifically, we apply a Plackett and Burman design to: 1) identify key processor parameters, 2) classify benchmarks based on how they affect the processor, and 3) analyze the effect of processor enhancements. Our results showed that, out of the 41 user-configurable parameters in SimpleScalar, only 10 had a significant effect on the execution time. Of those 10, the number of reorder buffer entries and the L2 cache latency were the two most significant ones, by far. Our results also showed that Instruction Precomputation\u9a74a value reuse-like microarchitectural technique\u9a74 primarily improves the processor's performance by relieving integer ALU contention.",
      "id": "40243"
    },
    {
      "title": "A programmable and scalable technique to design spintronic logic circuits based on magnetic tunnel junctions",
      "abstract": "Exciting developments are taking place in the field of spintronics, particularly with the advances in the fabrication and characterization of devices such as Magnetic Tunnel Junctions (MTJ). The distinction of spintronic devices from conventional electronic devices makes it challenging to design efficient, scalable and low power logic circuits with MTJs. We propose a programmable and scalable technique to design MTJ-based logic circuits that are capable of implementing any 2-input logic truth table. We present the energy-delay trade-offs of this design with respect to circuit parameters. We also demonstrate that this circuit can be scaled to a 6-input logic function without incurring an increase in the energy consumption.",
      "id": "40244"
    },
    {
      "title": "An evaluation of a compiler optimization for improving the performance of a coherence directory",
      "abstract": "Both hardware-controlled and compiler-directed mechanisms have been proposed for maintaining cache coherence in large-scale shared-memory multiprocessors, but both of these approaches have significant limitations. We examine the potential performance improvement of a new software-hardware controlled cache coherence mechanism. This approach augments the run-time information available to a directory-based coherence mechanism with compile-time analysis that statically identifies write references that cannot cause coherence problems and writes that should be written through to memory. These references are marked as not needing to send invalidation messages to thereby reduce the network traffic produced by the directory while maintaining cache consistency. For those memory references that are ambiguous, due to conditional branches, or due to the need for complex data flow analysis, for instance, the compiler conservatively marks the references and relies on the hardware directory to ensure coherence. Trace-driven simulations are used to emulate the compile-time analysis on memory traces and to estimate potential performance improvement that could be expected from a compiler performing this optimization on the Perfect Club benchmark programs. By reducing the number of invalidations, this optimized directory scheme is capable of reducing the processor-memory network traffic by up to 54 percent compared to an unoptimized directory mechanism. In addition, the overall miss ratio can be reduced up to 42 percent due to a corresponding reduction in the number of write misses.",
      "id": "40245"
    },
    {
      "title": "Improving Data Cache Performance via Address Correlation: An Upper Bound Study",
      "abstract": "Address correlation is a technique that links the addresses that reference the same data values. Using a detailed source-code level analysis, a recent study [1] revealed that different addresses containing the same data can often be correlated at run-time to eliminate on-chip data cache misses. In this paper, we study the upper-bound performance of an Address Correlation System (ACS), and discuss specific optimizations for a realistic hardware implementation. An ACS can effectively eliminate most of the L1 data cache misses by supplying the data from a correlated address already found in the cache to thereby improve the performance of the processor. For 10 of the SPEC CPU2000 benchmarks, 57 to 99% of all L1 data cache load misses can be eliminated, which produces an increase of 0 to 243% in the overall performance of a superscalar processor. We also show that an ACS with 1-2 correlations for a value can usually provide comparable performance results to that of the upper bound. Furthermore, a considerable number of correlations can be found within the same set in the L1 data cache, which suggests that a low-cost ACS implementation is possible.",
      "id": "40246"
    },
    {
      "title": "Design of a spintronic arithmetic and logic unit using magnetic tunnel junctions",
      "abstract": "Conventional electronics technology uses an electron's charge to store information and a current of electrons to transfer information. Spintronics technology, in contrast, uses an electron's 'spin' in addition to its charge to transfer and store information. Magnetic Tunnel Junctions (MTJ) are spintronic devices that exhibit two distinct resistance states due to the tunneling magnetoresistance (TMR) effect. Their properties can provide significant advantages over conventional electronics in the design of computer systems. We characterize some of the challenges in using spintronic technology in large systems, and describe a novel design technique called 'union with neutralization' to combine individual component designs into multi-functional units. We use this technique to present the design of an arithmetic and logical unit (ALU) using 20 MTJs and two CMOS-based sense amplifiers. The spintronics-based ALU has the potential to offer considerable area, timing, and power advantages over a conventional CMOS-based ALU.",
      "id": "40247"
    },
    {
      "title": "Address Correlation: Exceeding the Limits of Locality",
      "abstract": "We investigate a program phenomena, Address Correlation, which links addresses that reference the same data. This work shows that different addresses containing the same data can often be correlated at run-time to eliminate a load miss or a partial hit. For ten of the SPEC CPU2000 benchmarks, 57 to 99% of all L1 data cache load misses, and 4 to 85% of all partial hits, can be supplied from a correlated address already found in the cache. Our source code-level analysis shows that semantically equivalent information, duplicated references, and frequent values are the major causes of address correlations. We also show that, on average, 68% of the potential correlated addresses that could supply data on a miss of an address containing the same value can be correlated at run time. These correlated addresses correspond to an average of 62% of all misses in the benchmark programs tested.",
      "id": "40248"
    },
    {
      "title": "Accelerating the performance of stochastic encoding-based computations by sharing bits in consecutive bit streams",
      "abstract": "Stochastic encoding represents a value using the probability of ones in a random bit stream. Computation based on this encoding has good fault-tolerance and low hardware cost. However, one of its major issues is long processing time. We have to use a long enough bit stream to represent a value to guarantee that random fluctuations introduce only small errors to final computation results. For example, for most digital image processing algorithms, we need a 512-bit stream to represent an 8-bit pixel value stochastically to guarantee that the final computation error is less than 5%. To solve this issue, this paper proposes to share bits between adjacent bit streams to represent adjacent deterministic values. For example, in image processing applications, the bit stream which represents the current pixel value can share parts of the bits in the bit stream which represents the previous pixel value. We use an image contrast stretching algorithm to evaluate this method. Our experimental results show that the proposed methods can improve the performance by 90%.",
      "id": "40249"
    },
    {
      "title": "A Superassociative Tagged Cache Coherence Directory",
      "abstract": "Dynamically tagged directories are memory-efficient mechanisms for maintaining cache coherence in shared- memory multiprocessors. These directories use special- purpose caches of pointers that are subject to two types of overflow: 1) pointer overflow, which limits the maximum sharing of a memory block, and 2) set overflow, which forces the premature invalidation of cached blocks. We propose a superassociative tagged directory that can preserve some of the cached copies of a memory block when a set overflows by allowing multiple address tags in the same set to contain the same address value. Verilog descriptions are used to estimate its implementation cost and timing delay, and a multiprocessor cache simulator is used to evaluate its performance.",
      "id": "40250"
    },
    {
      "title": "A divide-and-conquer approach for solving singular value decomposition on a heterogeneous system",
      "abstract": "Singular value decomposition (SVD) is a fundamental linear operation that has been used for many applications, such as pattern recognition and statistical information processing. In order to accelerate this time-consuming operation, this paper presents a new divide-and-conquer approach for solving SVD on a heterogeneous CPU-GPU system. We carefully design our algorithm to match the mathematical requirements of SVD to the unique characteristics of a heterogeneous computing platform. This includes a high-performanc solution to the secular equation with good numerical stability, overlapping the CPU and the GPU tasks, and leveraging the GPU bandwidth in a heterogeneous system. The experimental results show that our algorithm has better performance than MKL's divide-and-conquer routine [18] with four cores (eight hardware threads) when the size of the input matrix is larger than 3000. Furthermore, it is up to 33 times faster than LAPACK's divide-and-conquer routine [17], 3 times faster than MKL's divide-and-conquer routine with four cores, and 7 times faster than CULA on the same device, when the size of the matrix grows up to 14,000. Our algorithm is also much faster than previous SVD approaches on GPUs.",
      "id": "40251"
    },
    {
      "title": "Analysis of Statistical Sampling in Microarchitecture Simulation: Metric, Methodology and Program Characterization",
      "abstract": "Statistical sampling, especially stratified random sampling, is a promising technique for estimating the performance of the benchmark program without executing the complete program on microarchitecture simulators or real machines. The accuracy of the performance estimate and the simulation cost depend on the three parameters, namely the interval size, the sample size, and the number of phases (or strata). Optimum values for these three parameters depends on the performance behavior of the program and the microarchitecture configuration being evaluated. In this paper, we quantify the effect of these three parameters and their interactions on the accuracy of the performance estimate and simulation cost. We use the Confidence Interval of estimated Mean (CIM), a metric derived from statistical sampling theory, to measure the accuracy of the performance estimate; we also discuss why CIM is an appropriate metric for this analysis. We use the total number of instructions simulated and the total number of samples measured as cost parameters. Finally, we characterize 21 SPEC CPU2000 benchmarks based on our analysis.",
      "id": "40252"
    },
    {
      "title": "On Memory System Design for Stochastic Computing.",
      "abstract": "Growing uncertainty in design parameters (and therefore, in design functionality) renders stochastic computing particularly promising, which represents and processes data as quantized probabilities. However, due to the difference in data representation, integrating conventional memory (designed and optimized for non-stochastic computing) in stochastic computing systems inevitably incurs a signific...",
      "id": "40253"
    },
    {
      "title": "A network status predictor to support dynamic scheduling in network-based computing systems",
      "abstract": "The management of networks has often been ignored in network-based computing systems due to the difficulty of estimating application programs' network latency and bandwidth requirements, and the difficulty of predicting the system network load. To help address this deficiency and thereby support dynamic network resource scheduling, we propose the network status predictor (NSP). This tool is a general and extensible network load monitor that introduces lower and upper latency prediction bounds. We evaluate its ability to dynamically predict TCP/IP end-to-end latency, with varying network loads using a cluster of SGI multiprocessors interconnected with a fibre channel network. Our results show that a combination of numerical predictors can be dynamically selected based on the network's recent state to produce better predictions than when using a single predictor alone",
      "id": "40254"
    },
    {
      "title": "Computation on Stochastic Bit Streams Digital Image Processing Case Studies",
      "abstract": "Maintaining the reliability of integrated circuits as transistor sizes continue to shrink to nanoscale dimensions is a significant looming challenge for the industry. Computation on stochastic bit streams, which could replace conventional deterministic computation based on a binary radix, allows similar computation to be performed more reliably and often with less hardware area. Prior work discussed a variety of specific stochastic computational elements (SCEs) for applications such as artificial neural networks and control systems. Recently, very promising new SCEs have been developed based on finite-state machines (FSMs). In this paper, we introduce new SCEs based on FSMs for the task of digital image processing. We present five digital image processing algorithms as case studies of practical applications of the technique. We compare the error tolerance, hardware area, and latency of stochastic implementations to those of conventional deterministic implementations using binary radix encoding. We also provide a rigorous analysis of a particular function, namely the stochastic linear gain function, which had only been validated experimentally in prior work.",
      "id": "40255"
    },
    {
      "title": "The synthesis of complex arithmetic computation on stochastic bit streams using sequential logic",
      "abstract": "The paradigm of logical computation on stochastic bit streams has several key advantages compared to deterministic computation based on binary radix, including error-tolerance and low hardware area cost. Prior research has shown that sequential logic operating on stochastic bit streams can compute non-polynomial functions, such as the tanh function, with less energy than conventional implementations. However, the functions that can be computed in this way are quite limited. For example, high order polynomials and non-polynomial functions cannot be computed using prior approaches. This paper proposes a new finite-state machine (FSM) topology for complex arithmetic computation on stochastic bit streams. It describes a general methodology for synthesizing such FSMs. Experimental results show that these FSM-based implementations are more tolerant of soft errors and less costly in terms of the area-time product that conventional implementations.",
      "id": "40257"
    },
    {
      "title": "A Compiler-Assisted Scheme for Adaptive Cache Coherence Enforcement",
      "abstract": "Cache coherence mechanisms in shared-memory multiprocessors typically use either updating or invalidating to prevent access to stale data, but neither enforcement strategy is the best choice for all programs. We present a compile-time optimization that uses the look-ahead capability of the compiler to select updating, invalidating, or neither for each write reference in a program to thereby produce the best overall memory performance. We implement this optimization in the Parafrase-2 compiler for memory references to scalar variables and use trace-driven simulations to compare the performance of this compiler-assisted adaptive coherence enforcement to hardware-only mechanisms. We find that this compiler optimization can produce miss ratios comparable to those produced by an updating-only mechanism while frequently reducing the total network traffic to below that produced by any of the hardware-only mechanisms.",
      "id": "40258"
    },
    {
      "title": "Cache coherence in large-scale shared-memory multiprocessors: issues and comparisons",
      "abstract": "Private data caches have not been as effective in reducing the average memory delay in multiprocessors as in uniprocessors due to data spreading among the processors, and due to the cache coherence problem. A wide variety of mechanisms have been proposed for maintaining cache coherence in large-scale shared memory multiprocessors making it difficult to compare their performance and implementation implications. To help the computer architect understand some of the trade-offs involved, this paper surveys current cache coherence mechanisms, and identifies several issues critical to their design. These design issues include: 1) the coherence detection strategy, through which possibly incoherent memory accesses are detected either statically at compile-time, or dynamically at run-time; 2) the coherence enforcement strategy, such as updating or invalidating, that is used to ensure that stale cache entries are never referenced by a processor; 3) how the precision of block sharing information can be changed to trade-off the implementation cost and the performance of the coherence mechanism; and 4) how the cache block size affects the performance of the memory system. Trace-driven simulations are used to compare the performance and implementation impacts of these different issues. In addition, hybrid strategies are presented that can enhance the performance of the multiprocessor memory system by combining several different coherence mechanisms into a single system.",
      "id": "40259"
    },
    {
      "title": "The NanoBox project: exploring fabrics of self-correcting logic blocks for high defect rate molecular device technologies",
      "abstract": "Trends indicate that emerging process technologies, including molecular computing, will experience an increase in the number of noise induced errors and device defects. In this paper, we in- troduce the NanoBox, a logic lookup table with fault tolerance coding applied to the lookup table bit string. In this way, we contain and self-correct errors within the lookup table, thereby presenting a robust logic block to higher levels of logic design. We explore five different NanoBox coding techniques. We also ex- amine the cost of implementing two different circuit blocks using a homogenous fabric of NanoBox logic elements: 1) a floating point control unit from the IBM Power4 microprocessor and 2) a four-instruction ALU. In this initial investigation, our results are not meant to draw definitive conclusions about any specific NanoBox implementation, but rather to spur discussion and ex- plore the feasibility of fine-grained error correction techniques in molecular computing systems.",
      "id": "40260"
    },
    {
      "title": "An efficient implementation of numerical integration using logical computation on stochastic bit streams",
      "abstract": "Numerical integration is a widely used approach for computing an approximate result of a definite integral. Conventional digital implementations of numerical integration using binary radix encoding are costly in terms of hardware and have long computational delay. This work proposes a novel method for performing numerical integration based on the paradigm of logical computation on stochastic bit streams. In this paradigm, ordinary digital circuits are employed but they operate on stochastic bit streams instead of deterministic values; the signal value is encoded by the probability of obtaining a one versus a zero in the streams. With this type of computation, complex arithmetic operations can be implemented with very simple circuitry. However, typically, such stochastic implementations have long computational delay, since long bit streams are required to encode precise values. This paper proposes a stochastic design for numerical integration characterized by both small area and short delay - so, in contrast to previous applications, a win on both metrics. The design is based on mathematical analysis that demonstrates that the summation of a large number of terms in the numerical integration could lead to a significant delay reduction. An architecture is proposed for this task. Experiments confirm that the stochastic implementation has smaller area and shorter delay than conventional implementations.",
      "id": "40261"
    },
    {
      "title": "Logical Computation on Stochastic Bit Streams with Linear Finite-State Machines",
      "abstract": "Most digital systems operate on a positional representation of data, such as binary radix. An alternative is to operate on random bit streams where the signal value is encoded by the probability of obtaining a one versus a zero. This representation is much less compact than binary radix. However, complex operations can be performed with very simple logic. Furthermore, since the representation is uniform, with all bits weighted equally, it is highly tolerant of soft errors (i.e., bit flips). Both combinational and sequential constructs have been proposed for operating on stochastic bit streams. Prior work has shown that combinational logic can implement multiplication and scaled addition effectively while linear finite-state machines (FSMs) can implement complex functions such as exponentiation and tanh effectively. Prior work on stochastic computation has largely been validated empirically.This paper provides a rigorous mathematical treatment of stochastic implementation of complex functions such as exponentiation and tanh implemented using linear FSMs. It presents two new functions, an absolute value function and exponentiation based on an absolute value, motivated by specific applications. Experimental results show that the linear FSM-based constructs for these functions have smaller area-delay products than the corresponding deterministic constructs. They also are much more tolerant of soft errors.",
      "id": "40262"
    },
    {
      "title": "The Effect of using State-Based Priority Information in a Shared-Memory Multiprocessor Cache Replacement Policy",
      "abstract": " The cache replacement policy is one of the factorsthat determines the effectiveness of cache memories.In this paper, we study the impact of incorporating thecache block coherence state information in the Random replacement policy in a shared--memory multiprocessor.We assign replacement priority to each cacheblock within a set based on its state. To reduce theprobability of replacing a recently accessed block andto adapt to the program's access patterns, we also associatewith each set... ",
      "id": "40263"
    },
    {
      "title": "Write buffer design for cache-coherent shared-memory multiprocessors",
      "abstract": "We evaluate the performance impact of two different write-buffer configurations (one word per buffer entry and one block per buffer entry) and two different write policies (write-through and write-back), when using the partial block invalidation coherence mechanism in a shared-memory multiprocessor. Using an execution-driven simulator, we find that the one word per entry buffer configuration with a write-back policy is preferred for small write-buffer sizes when both buffers have an equal number of data words, and when they have equal hardware cost. Furthermore, when partial block invalidation is supported, we find that a write-through policy is preferred over a write-back policy due to its simpler cache hit detection mechanism, its elimination of write-back transactions, and its competitive-performance when the write-buffer is relatively large.",
      "id": "40264"
    },
    {
      "title": "Coarse-grained speculative execution in shared-memory multiprocessors",
      "abstract": " This thesis presents a new parallelization model, called coarse-grained thread pipelining, for exploitingcoarse-grained parallelism from general-purpose application programs in shared-memorymultiprocessor systems. This parallelization model, which is based on the fine-grained threadpipelining model proposed for the superthreaded architecture [7], allows concurrent execution ofloop iterations in a pipelined fashion with run-time data dependence checking and control speculation.The... ",
      "id": "40265"
    },
    {
      "title": "Deferred updates for flash-based storage",
      "abstract": "The NAND flash memory based storage has faster read, higher power savings, and lower cooling cost compared to the conventional rotating magnetic disk drive. However, in case of flash memory, read and write operations are not symmetric. Write operations are much slower than read operations. Moreover, frequent update operations reduce the lifetime of the flash memory. Due to the faster read performance, flash-based storage is particularly attractive for the read-intensive database workloads, while it can produce poor performance when used for the update-intensive database workloads. This paper aims to improve write performance and lifetime of flash-based storage for the update-intensive workloads. In particular, we propose a new hierarchical approach named as deferred update methodology. Instead of directly updating the data records, first we buffer the changes due to update operations as logs in two intermediate in-flash layers. Next, we apply multiple update logs in bulk to the data records. Experimental results show that our proposed methodology significantly improves update processing overhead and longevity of the flash-based storages.",
      "id": "40266"
    },
    {
      "title": "Layered View Of Qos Issues In Ip-Based Mobile Wireless Networks",
      "abstract": "With the convergence of wireless communication and IP-based networking technologies, future IP-based wireless networks are expected to support real-time multimedia. IP services over wireless networks (e.g. wireless access to Internet) enhance the mobility and flexibility of traditional IP network users. Wireless networks extend the current IP service infrastructure to a mix of transmission media, bandwidth, costs, coverage, and service agreements, requiring enhancements to the IP protocol layers in wireless networks. Furthermore, QoS provisioning is required at various layers of the IP protocol stack to guarantee different types of service requests, giving rise to issues related to cross-layer design methodology. This paper reviews issues and prevailing solutions to performance enhancements and QoS provisioning for IP services over mobile wireless networks from a layered view. Copyright (c) 2006 John Wiley & Sons, Ltd.",
      "id": "40267"
    },
    {
      "title": "Sampling-based garbage collection metadata management scheme for flash-based storage",
      "abstract": "Existing garbage collection algorithms for the flash-based storage use score-based heuristics to select victim blocks for reclaiming free space and wear leveling. The score for a block is estimated using metadata information such as age, block utilization, and erase count. To quickly find a victim block, these algorithms maintain a priority queue in the SRAM of the storage controller. This priority queue takes O(K) space, where K stands for flash storage capacity in total number of blocks. As the flash capacity scales to larger size, K also scales to larger value. However, due to higher price per byte, SRAM will not scale proportionately. In this case, due to SRAM scarcity, it will be challenging to implement a larger priority queue in the limited SRAM of a large-capacity flash storage. In addition to space issue, with any update in the metadata information, the priority queue needs to be continuously updated, which takes O(lg(K)) operations. This computation overhead also increases with the increase of flash capacity. In this paper, we have taken a novel approach to solve the garbage collection metadata management problem of a large-capacity flash storage. We propose a sampling-based approach to approximate existing garbage collection algorithms in the limited SRAM space. Since these algorithms are heuristic-based, our sampling-based algorithm will perform as good as unsampled (original) algorithm, if we choose good samples to make garbage collection decisions. We propose a very simple policy to choose samples. Our experimental results show that small number of samples are good enough to emulate existing garbage collection algorithms.",
      "id": "40268"
    },
    {
      "title": "An Overview of Time-Based Computing with Stochastic Constructs.",
      "abstract": "Computing on time-based data is a recent evolution of research in stochastic computing. As with stochastic computing, complex functions can be computed with remarkably low area cost. Unlike stochastic computing, the latency and energy efficiency are very favorable compared to computations on conventional binary radix. In this article, the authors review and evaluate the design and implementation o...",
      "id": "40269"
    },
    {
      "title": "Exploiting the Impact of Database System Configuration Parameters: A Design of Experiments Approach",
      "abstract": "Tuning database system configuration parameters to proper values acc ording to the expected query workload plays a very important role in determining DBMS performance. H owever, the number of configuration parameters in a DBMS is very large. Furthermore, typicalquery workloads have a large number of constituent queries, which makes tuning very time and effort in tensive. To reduce tuning time and effort, database administrators rely on their experience and some ru les of thumb to select a set of important configuration parameters for tuning. Nonetheless, as a statistica lly rigorous methodology is not used, time and effort may be wasted by tuning those parameters which may have no or marginal effects on the DBMS performance for the given query workload. Database a dministrators also use compressed query workloads to reduce tuning time. If not carefully sele cted, the compressed query workload may fail to include a query which may reveal important performa nce bottleneck parameters. In this article, we provide a systematic approach to help the database adminis trators in tuning activities. We achieve our goals through two phases. First, we estimate the effects of th e configuration parameters for each workload query. The effects are estimated through a design of e xperiments-basedPLACKETT & BURMAN design methodology where the number of experiments required is linearly proportional to the number of input parameters. Second, we exploit the estimated effects to:1) rank DBMS configuration parameters for a given query workload based on their impact on the DBMS performance, and 2) select a compressed query workload that preserves the fidelity of the originalworkload. Experimental results using PostgreSQL and TPC-H query workload show that our methodolog ies are working correctly.",
      "id": "40270"
    },
    {
      "title": "A Comparative Analysis Of Parallel Programming Language Complexity And Performance",
      "abstract": "Several parallel programming languages, libraries and environments have been developed to ease the task of writing programs for multiprocessors. Proponents of each approach often point out various language features that are designed to provide the programmer with a simple programming interface. However, virtually no data exist that quantitatively evaluate the relative ease of use of different parallel programming languages. The paper borrows techniques from the software engineering field to quantify the complexity of three predominant programming models: shared-memory, message-passing and high-performance Fortran, It is concluded that traditional software complexity metrics are effective indicators of the relative complexity of parallel programming languages. The impact of complexity on run-time performance is also discussed in the context of message-passing vs. HPF on an IBM SP2. (C) 1998 John Wiley & Sons, Ltd.",
      "id": "40271"
    },
    {
      "title": "Communicating Quality of Service Requirements to an Object-Based Storage Device",
      "abstract": "Obtaining consistent bandwidth with predictable latency from disk-based storage systems has proven difficult due to the storage system's inability to understand Quality of Service (QoS) requirements. In this paper, we present a feasibility study of QoS with the Object-based Storage Device (OSD) specification. We look at OSD's ability to provide QoS guarantees for consistent bandwidth with predictable latency. Included in this paper is a description of QoS requirements of a sample application and how these requirements are translated into parameters that are then communicated to, and interpreted by, the OSD. Implementation problems lead to the failure of a hard real-time QoS model, but this failure is not due to the OSD protocol. The paper concludes with a description of how well the Revision 9 OSD standard (OSDR9) is able to accommodate QoS. We provide suggestions for improving the OSD specification and its ability to communicate QoS requirements.",
      "id": "40272"
    },
    {
      "title": "MinneSPEC: A New SPEC Benchmark Workload for Simulation-Based Computer Architecture Research",
      "abstract": "Computer architects must determine how tomost effectively use finite computational resources whenrunning simulations to evaluate new architectural ideas.To facilitate efficient simulations with a range of benchmarkprograms, rn have developed the MinneSPEC inputset for the SPEC CPU 2000 benchmark suite. Thisnew workload allows computer architects to obtain simulationresults in a reasonable time using existing sirnulators.While the MinneSPEC workload is derived from thestandard SPEC CPU 2000 warklcad, it is a valid benchmarksuite in and of itself for simulation-based research.MinneSPEC also may be used to run Iarge numbers ofsimulations to find \"sweet spots\" in the evaluation parameterspace. This small number of promising designpoints subsequently may be investigated in more detailwith the full SPEC reference workload. In the processof developing the MinneSPEC datasets, we quantify itsdifferences in terms of function-level execution patterns,instruction mixes, and memory behaviors compared tothe SPEC programs when executed with the reference inputs.We find that for some programs, the MinneSPECprofiles match the SPEC reference dataset program behaviorvery closely. For other programs, however, theMinneSPEC inputs produce significantly different programbehavior. The MinneSPEC workload has been recognizedby SPEC and is distributed with Version 1.2 andhigher of the SPEC CPU 2000 benchmark suite.",
      "id": "40273"
    },
    {
      "title": "Complexity and Performance in Parallel Programming Languages",
      "abstract": "Several parallel programming languages, libraries and environments have been developed to ease the task of writing programs for multiprocessors. Proponents of each approach often point out various language features that are designed to provide the programmer with a simple programming interface. However, virtually no data exists that quantitatively evaluates the relative ease of use of different parallel programming languages. The following paper borrows techniques from the software engineering field to quantify the complexity of three predominate programming models: shared memory, message passing and High-Performance Fortran. It is concluded that traditional software complexity metrics are effective indicators of the relative complexity of parallel programming languages. The impact of complexity on run-time performance is also discussed in the context of message-passing versus HPF on an IBM SP2.",
      "id": "40274"
    },
    {
      "title": "Compiler-Directed Classification of Value Locality Behavior",
      "abstract": "Abstract: Value prediction has been suggested as a way to increase the instruction-level parallelism available in a superscalar processor. One of the potential difficulties in cost-effectively predicting values for a given instruction, however, is selecting the proper type of predictor. We propose a compiler-directed classification scheme that statically partitions instructions in a program into several groups, each of which is associated with a specific value predictability pattern. This value predictability pattern is encoded into the instructions to identify the type of value predictor that will be best suited for each instruction at run-time. Both an idealized profile-based compiler implementation and an implementation based on the GCC compiler are studied. We use execution-driven simulation and SPEC95 and SPEC2000 benchmarks to study the performance of this approach. This work also demonstrates the connection between value locality and source-level program structures thereby leading to a deeper understanding of the causes of this behavior.",
      "id": "40275"
    },
    {
      "title": "Improving nanoelectronic designs using a statistical approach to identify key parameters in circuit level SEU simulations",
      "abstract": "One of the key challenges in nanoelectronics design is the decreasing reliability due to radiation induced single-event upsets. Without detailed device level simulations or physical experimentation, circuit level models can generate misleading reliability information. We present the results from a screening experiment to identify significant parameters in circuit level SEU simulations. We show that cell supply voltage, sizing parameters, and transient waveform descriptions have an important impact on design and should therefore be considered with care in circuit level designs. Larger variations in parameters can lead to soft error rate estimates that vary by more than 4 orders of magnitude, even small variations can lead to 15x variation in soft error rate estimation for a design. We present our methodology for screening and a ranking based on significance of several parameters involved in soft error simulation at the SPICE level.",
      "id": "40276"
    },
    {
      "title": "Accelerating geoscience and engineering system simulations on graphics hardware",
      "abstract": "Many complex natural systems studied in the geosciences are characterized by simple local-scale interactions that result in complex emergent behavior. Simulations of these systems, often implemented in parallel using standard central processing unit (CPU) clusters, may be better suited to parallel processing environments with large numbers of simple processors. Such an environment is found in graphics processing units (GPUs) on graphics cards. This paper discusses GPU implementations of three example applications from computational fluid dynamics, seismic wave propagation, and rock magnetism. These candidate applications involve important numerical modeling techniques, widely employed in physical system simulations, that are themselves examples of distinct computing classes identified as fundamental to scientific and engineering computing. The presented numerical methods (and respective computing classes they belong to) are: (1) a lattice-Boltzmann code for geofluid dynamics (structured grid class); (2) a spectral-finite-element code for seismic wave propagation simulations (sparse linear algebra class); and (3) a least-squares minimization code for interpreting magnetic force microscopy data (dense linear algebra class). Significant performance increases (between 10x and 30x in most cases) are seen in all three applications, demonstrating the power of GPU implementations for these types of simulations and, more generally, their associated computing classes.",
      "id": "40277"
    },
    {
      "title": "Impact of spintronic memory on multicore cache hierarchy design.",
      "abstract": "Spintronic memory [spin-transfer torque-magnetic random access memory (STT-MRAM)] is an attractive alternative technology to CMOS since it offers higher density and virtually no leakage current. Spintronic memory continues to require higher write energy, however, presenting a challenge to memory hierarchy design when energy consumption is a concern. This study motivates the use of STT-MRAM for the...",
      "id": "40278"
    },
    {
      "title": "Characterizing and Comparing Prevailing Simulation Techniques",
      "abstract": "Due to the simulation time of the reference input set, architects often use alternative simulation techniques. Although these alternatives reduce the simulation time, what has not been evaluated is their accuracy relative to the reference input set, and with respect to each other. To rectify this deficiency, this paper uses three methods to characterize the reduced input set, truncated execution, and sampling simulation techniques while also examining their speed versus accuracy trade-off and configuration dependence. Finally, to illustrate the effect that a technique could have on the apparent speedup results, we quantify the speedups obtained with two processor enhancements. The results show that: 1) The accuracy of the truncated execution techniques was poor for all three characterization methods and for both enhancements, 2) The characteristics of the reduced input sets are not reference-like, and 3) SimPoint and SMARTS, the two sampling techniques, are extremely accurate and have the best speed versus accuracy trade-offs. Finally, this paper presents a decision tree which can help architects choose the most appropriate technique for their simulations.",
      "id": "40279"
    },
    {
      "title": "SARD: A statistical approach for ranking database tuning parameters",
      "abstract": "The ability of a database management system (DBMS) to detect problems or problem trends (which have not yet manifested as problems) and either take corrective actions, and/or provide advice or an automated notification to the database administrator (DBA) ...",
      "id": "40280"
    },
    {
      "title": "Polysynchronous Clocking: Exploiting the Skew Tolerance of Stochastic Circuits.",
      "abstract": "In the paradigm of stochastic computing, arithmetic functions are computed on randomized bit streams. The method naturally and effectively tolerates very high clock skew. Exploiting this advantage, this paper introduces polysynchronous clocking, a design strategy in which clock domains are split at a very fine level. Each domain is synchronized by an inexpensive local clock. Alternatively, the ske...",
      "id": "40281"
    },
    {
      "title": "The Recursive NanoBox Processor Grid: A Reliable System Architecture for Unreliable Nanotechnology Devices",
      "abstract": "Advanced molecular nanotechnology devices are expectedto have exceedingly high transient fault rates and largenumbers of inherent device defects compared to conventionalCMOS devices. We introduce the Recursive NanoBoxProcessor Grid as an application specific, fault-tolerant,parallel computing system designed for fabrication with unreliablenanotechnology devices. In this initial study weconstruct VHDL models of the NanoBox Processor cellALU and evaluate the effectiveness of our recursive faultmasking approach in the presence of random transient errors.Our analysis shows that the ALU can calculate correctly100 percent of the time with raw FIT (failures in time)rates as high as 10{23}. We achieve this error correction withan area overhead on the order of 9x, which is quite reasonablegiven the high integration densities expected with nanodevices.",
      "id": "40282"
    },
    {
      "title": "CIM: A Reliable Metric for Evaluating Program Phase Classifications",
      "abstract": "We propose the use of the Confidence Interval of estimated Mean (CIM), a metric based on statistical sampling theory, to evaluate the quality of a given phase classification and for comparing different phase classification schemes. Previous research on phase classification used the Weighted Average of Coefficient of Variation (CoVwa) to estimate phase classification quality. We found that the phase quality indicated by CoVwa could be inconsistent across different phase classifications. We explain the reasons behind this inconsistency and demonstrate the inconsistency using data from several SPEC CPU2000 benchmark programs. We show that the Confidence Interval of estimated Mean (CIM) correctly estimates the quality of phase classification with a meaningful statistical interpretation.",
      "id": "40283"
    },
    {
      "title": "Performance Analysis and Prediction of Processor Scheduling Strategies in Multiprogrammed Shared-Memory Multiprocessors",
      "abstract": " Small-scale shared-memory multiprocessors are commonly used in a workgroup environmentwhere multiple applications, both parallel and sequential, are executed concurrentlywhile sharing the processors and other system resources. To utilize the processors efficiently,an effective scheduling strategy is required. In this paper, we use performance data obtainedfrom an SGI multiprocessor to evaluate several processor scheduling strategies. We examinegang scheduling (coscheduling), static space... ",
      "id": "40284"
    },
    {
      "title": "Coarse-grained thread pipelining: a speculative parallel execution model for shared-memory multiprocessors",
      "abstract": "This paper presents a new parallelization model, called coarse-grained thread pipelining, for exploiting speculative coarse-grained parallelism from general-purpose application programs in shared-memory multiprocessor systems. This parallelization model, which is based on the fine-grained thread pipelining model proposed for the superthreaded architecture, allows concurrent execution of loop iterations in a pipelined fashion with runtime data-dependence checking and control speculation. The speculative execution combined with the runtime dependence checking allows the parallelization of a variety of program constructs that cannot be parallelized with existing runtime parallelization algorithms. The pipelined execution of loop iterations in this new technique results in lower parallelization overhead than in other existing techniques. We evaluated the performance of this new model using some real applications and a synthetic benchmark. These experiments show that programs with a sufficiently large grain size compared to the parallelization overhead obtain significant speedup using this model. The results from the synthetic benchmark provide a means for estimating the performance that can be obtained from application programs that will be parallelized with this model. The library routines developed for this thread pipelining model are also useful for evaluating the correctness of the codes generated by the superthreaded compiler and in debugging and verifying the simulator for the superthreaded processor.",
      "id": "40285"
    },
    {
      "title": "Efficient Use of Dynamically tagged Directories Through Compiler Analysis",
      "abstract": "Dynamiically tagged directories have been recently proposed as a memory-efficient mechanism for maintaining cache coherence in large-scale shared-memory multiprocessors. In order to efficiently use these directories, the number of pointer operations must be minimized and pointers should be allocated as late as possible. If pointers are allocated too early, frequent pointer overflow will occur, which in turn may cause cache thrashing.",
      "id": "40286"
    },
    {
      "title": "Romano: autonomous storage management using performance prediction in multi-tenant datacenters",
      "abstract": "Workload consolidation is a key technique in reducing costs in virtualized datacenters. When considering storage consolidation, a key problem is the unpredictable performance behavior of consolidated workloads on a given storage system. In practice, this often forces system administrators to grossly overprovision storage to meet application demands. In this paper, we show that existing modeling techniques are inaccurate and ineffective in the face of heterogenous devices. We introduce Romano, a storage performance management system designed to optimize truly heterogeneous virtualized datacenters. At its core, Romano constructs and adapts approximate workload-specific performance models of storage devices automatically, along with prediction intervals. It then applies these models to allow highly efficient IO load balancing. End-to-end experiments demonstrate that Romano reduces prediction error by 80% on average compared with existing techniques. The result is improved load balancing with lowered variance by 82% and reduced average and maximum latency observed across the storage systems by 52% and 78%, respectively.",
      "id": "40287"
    },
    {
      "title": "MMV: a metamodeling based microprocessor validation environment",
      "abstract": "With increasing levels of integration of multiple processing cores and new features to support software functionality, recent generations of microprocessors face difficult validation challenges. The systematic validation approach starts with defining the correct behaviors of the hardware and software components and their interactions. This requires new modeling paradigms that support multiple levels of abstraction. Mutual consistency of models at adjacent levels of abstraction is crucial for manual refinement of models from the full chip level to production register transfer level, which is likely to remain the dominant design methodology of complex microprocessors in the near future. In this paper, we present microprocessor modeling and validation environment (MMV), a validation environment based on metamodeling, that can be used to create models at various abstraction levels and to generate most of the important validation collaterals, viz., simulators, checkers, coverage, and test generation tools. We illustrate the functionalities in MMV by modeling a 32-bit reduced instruction set computer processor at the system, instruction set architecture, and microarchitecture levels. We show by examples how consistency across levels is enforced during modeling and also how to generate constraints for automatic test generation.",
      "id": "40288"
    },
    {
      "title": "Dynamic task scheduling using online optimization",
      "abstract": "Algorithms for scheduling independent tasks on to the processors of a multiprocessor system must trade-off processor load balance, memory locality, and scheduling overhead. Most existing algorithms, however, do not adequately balance these conflicting factors. This paper introduces the self-adjusting dynamic scheduling (SADS) class of algorithms that use a unified cost model to explicitly account for these factors at runtime. A dedicated processor performs scheduling in phases by maintaining a tree of partial schedules and incrementally assigning tasks to the least-cost schedule. A scheduling phase terminates whenever any processor becomes idle, at which time partial schedules are distributed to the processors. An extension of the basic SADS algorithm, called DBSADS, controls the scheduling overhead by giving higher priority to partial schedules with more task-to-processor assignments. These algorithms are compared to two distributed scheduling algorithms within a database application on an Intel Paragon distributed memory multiprocessor system.",
      "id": "40289"
    },
    {
      "title": "An effective processor allocation strategy for multiprogrammed shared-memory multiprocessors",
      "abstract": "Existing techniques for sharing the processing resources in multiprogrammed shared-memory multiprocessors, such as time-sharing, space-sharing, and gang-scheduling, typically sacrifice the performance of individual parallel applications to improve overall system utilization. We present a new processor allocation technique called Loop-Level Process Control (LLPC) that dynamically adjusts the number of processors an application is allowed to use for the execution of each parallel section of code, based on the current system load. This approach exploits the maximum parallelism possible for each application without overloading the system. We implement our scheme on a Silicon Graphics Challenge multiprocessor system and evaluate its performance using applications from the Perfect Club benchmark suite and synthetic benchmarks. Our approach shows significant improvements over traditional time-sharing and gang-scheduling. It has performance comparable to, or slightly better than, static space-sharing, but our strategy is more robust since, unlike static space-sharing, it does not require a priori knowledge of the applications' parallelism characteristics.",
      "id": "40290"
    },
    {
      "title": "History index of correct computation for fault-tolerant nano-computing",
      "abstract": "Future nanoscale devices are expected to be more fragile and sensitive to external influences than conventional CMOS-based devices. Researchers predict that it will no longer be possible to test a device and then throw it away if it is found to be defective, as every circuit is expected to have multiple hard and soft defects. Fundamentally new fault-tolerant architectures are required to produce reliable systems that will survive with manufacturing defects and transient faults. This paper introduces the History Index of Correct Computation (HICC) as a run-time reconfiguration technique for fault-tolerant nano-computing. This approach identifies reliable blocks on-the-fly by monitoring the correctness of their outputs and forwarding only good results, ignoring the results from unreliable blocks. Simulation results show that history-based TMR modules offer a better response to fault tolerance at the module level than do conventional fault-tolerant approaches when the faults are nonuniformly distributed among redundant units. A correct computation rate of 99% is achieved despite a 13% average injected fault rate, when one of the redundant units and the decision unit are fault-free as well as when both have a low injected fault rate of 0.1%. A correct computation rate of 89% is achieved when faults are nonuniformly distributed at an average fault rate of 11% and fault rate in the decision unit is 0.5%. The robustness of the history-based mechanism is shown to be better than both majority voting and a Hamming detection and correction code.",
      "id": "40291"
    },
    {
      "title": "Data prefetch mechanisms",
      "abstract": "The expanding gap between microprocessor and DRAM performance has necessitated the use of increasingly aggressive techniques designed to reduce or hide the latency of main memory access. Although large cache hierarchies have proven to be effective in reducing this latency for the most frequently used data, it is still not uncommon for many programs to spend more than half their run times stalled on memory requests. Data prefetching has been proposed as a technique for hiding the access latency of data referencing patterns that defeat caching strategies. Rather than waiting for a cache miss to initiate a memory fetch, data prefetching anticipates such misses and issues a fetch to the memory system in advance of the actual memory reference. To be effective, prefetching must be implemented in such a way that prefetches are timely, useful, and introduce little overhead. Secondary effects such as cache pollution and increased memory bandwidth requirements must also be taken into consideration. Despite these obstacles, prefetching has the potential to significantly improve overall program execution time by overlapping computation with memory accesses. Prefetching strategies are diverse, and no single strategy has yet been proposed that provides optimal performance. The following survey examines several alternative approaches, and discusses the design tradeoffs involved when implementing a data prefetch strategy.",
      "id": "40292"
    },
    {
      "title": "An FPGA implementation of a Restricted Boltzmann Machine classifier using stochastic bit streams",
      "abstract": "Artificial neural networks (ANNs) usually require a very large number of computation nodes and can be implemented either in software or directly in hardware, such as FPGAs. Software-based approaches are offline and not suitable for real-time applications, but they support a large number of nodes. FPGA-based implementations, in contrast, can greatly speedup the computation time. However, resource limitations in an FPGA restrict the maximum number of computation nodes in hardware-based approaches. This work exploits stochastic bit streams to implement the Restricted Boltzmann Machine (RBM) handwritten digit recognition application completely on an FPGA. Exploiting this approach saves a large number of hardware resources making the FPGA-based implementation of large ANNs feasible.",
      "id": "40293"
    },
    {
      "title": "Enhancing the Memory Performance of Embedded Systems with the Flexible Sequential and Random Access Memory",
      "abstract": "The on-chip memory performance of embedded systems directly affects the system designers' decision about how to allocate expensive silicon area. We investigate a novel memory architecture, flexible sequential and random access memory (FSRAM), for embedded systems. To realize sequential accesses, small \"links\" are added to each row in the RAM array to point to the next row to be prefetched. The potential cache pollution is ameliorated by a small sequential access buffer (SAB). To evaluate the architecture-level performance of FSRAM, we run the Mediabench benchmark programs [1] on a modified version of the Simplescalar simulator [2]. Our results show that the FSRAM improves the performance of a baseline processor with a 16KB data cache up to 55%, with an average of 9%. We also designed RTL and SPICE models of the FSRAM [3], which show that the FSRAM significantly improves memory access time, while reducing power consumption, with negligible area overhead.",
      "id": "40294"
    },
    {
      "title": "Fault tolerance for nanotechnology devices at the bit and module levels with history index of correct computation.",
      "abstract": "Future nano-scale devices are expected to shrink to ever smaller dimensions, to operate at low voltages and high frequencies, to be more sensitive to environmental influences and to be characterised by high dynamic fault rates and defect densities. Fundamentally new fault-tolerant architectures are required in order to produce reliable systems that will operate correctly. Simple replication of mic...",
      "id": "40295"
    },
    {
      "title": "BloomFlash: Bloom Filter on Flash-Based Storage",
      "abstract": "The bloom filter is a probabilistic data structure that provides a compact representation of a set of elements. To keep false positive probabilities low, the size of the bloom filter must be dimensioned a priori to be linear in the maximum number of keys inserted, with the linearity constant ranging typically from one to few bytes. A bloom filter is most commonly used as an in memory data structure, hence its size is limited by the availability of RAM space on the machine. As datasets have grown over time to Internet scale, so have the RAM space requirements of bloom filters. If sufficient RAM space is not available, we advocate that flash memory may serve as a suitable medium for storing bloom filters, since it is about one-tenth the cost of RAM per GB while still providing access times orders of magnitude faster than hard disk. We present BLOOMFLASH, a bloom filter designed for flash memory based storage, that provides a new dimension of trade off with bloom filter access times to reduce RAM space usage (and hence system cost). The simple design of a single flat bloom filter on flash suffers from many performance bottlenecks, including in-place bit updates that are inefficient on flash and multiple reads and random writes spread out across many flash pages for a single lookup or insert operation. To mitigate these performance bottlenecks, BLOOMFLASH leverages two key design innovations: (i) buffering bit updates in RAM and applying them in bulk to flash that helps to reduce random writes to flash, and (ii) a hierarchical bloom filter design consisting of component bloom filters, stored one per flash page, that helps to localize reads and writes on flash. We use two real-world data traces taken from representative bloom filter applications to drive and evaluate our design. BLOOMFLASH achieves bloom filter access times in the range of few tens of microseconds, thus allowing up to order of tens of thousands operations per sec.",
      "id": "40296"
    },
    {
      "title": "A Distributed Hardware Mechanism for Process Synchronization on Shared-Bus Multiprocessors",
      "abstract": "Several techniques have been used to reduce the performance impact of process synchronization in fine-grained multiprocessor systems. These existing techniques tend to have long synchronization times or high shared-bus use, or they require complex and expensive hardware. A new technique is presented that uses distributed hardware locking queues to reduce both contention and latency to the minimum values that can be obtained using a shared-bus. This technique is shown to require at most two shared-bus transactions, with one transaction being typical. The latency for process continuation after obtaining a lock is reduced to near zero. Barrier synchronization using this distributed mechanism requires only one shared-bus transaction per processor involved in the barrier. This new technique is scalable and applicable to both new architectures and to existing systems, and is less complex than other hardware solutions.",
      "id": "40297"
    },
    {
      "title": "The superthreaded processor architecture",
      "abstract": "The common single-threaded execution model limits processors to exploiting only the relatively small amount of instruction-level parallelism that is available in application programs. The superthreaded processor, on the other hand, is a concurrent multithreaded architecture (CMA) that can exploit the multiple granularities of parallelism that are available in general-purpose application programs. Unlike other CMAs that rely primarily on hardware for run-time dependence detection and speculation, the superthreaded processor combines compiler-directed thread-level speculation of control and data dependences with run-time data dependence verification hardware. This hybrid of a superscalar processor and a multiprocessor-on-a-chip can utilize many of the existing compiler techniques used in traditional parallelizing compilers developed for multiprocessors. Additional unique compiler techniques, such as the conversion of data speculation into control speculation, are also introduced to generate the superthreaded code and to enhance the parallelism between threads. A detailed execution-driven simulator is used to evaluate the performance potential of this new architecture. It is found that a superthreaded processor can achieve good performance on complex application programs through this close coupling of compile-time and run-time information",
      "id": "40298"
    },
    {
      "title": "Combining hardware and software cache coherence strategies",
      "abstract": "Efficiently maintaining cache coherence is a major problem in large-scale shared memory mul- tiprocessors. Hardware directory schemes have very high memory requirements, while software-directed schemes must rely on imprecise compile-time memory disambiguation. Recently proposed dynamic directory schemes allocate pointers to blocks only as they are referenced, which significantly reduces their memory requirements, but they still allocate pointers to blocks that do not need them. We show how compiler mark- ing can further reduce the directory size by allocating pointers only when necessary. Using trace-driven simulations, we find that the performance of this new approach is comparable to other coherence schemes, but with significantly lower memory requirements.",
      "id": "40299"
    },
    {
      "title": "Independent Component Analysis and Evolutionary Algorithms for Building Representative Benchmark Subsets",
      "abstract": "This work addresses the problem of building representative subsets of benchmarks from an original large set of benchmarks, using statistical analysis techniques. The subsets should be developed in this way to include only the necessary information for evaluating the performance of a computer system or application. The development of representative workloads is not a trivial procedure, since incorrectly selecting benchmarks the representative subset can produce erroneous results. A number of statistical analysis techniques have been developed for identifying representative workloads. The goal of these approaches is to reduce the dimensionality of the original set of benchmarks prior to identifying similar benchmarks. In this work we propose a combination of Independent Component Analysis (ICA) and Evolutionary Algorithm (EA) as a more efficient way for reducing the computational complexity of the problem and the redundant information of the original set of benchmarks. Experimental results validate that the proposed technique generates more representative workloads than prior techniques.",
      "id": "402100"
    },
    {
      "title": "Using ECN Marks to Improve TCP Performance over Lossy Links",
      "abstract": "TCP was designed for wireline networks, where loss events are mostly caused by network congestion. The congestion control mechanism of current TCP uses loss events as the indicator of congestion, and reduces its congestion window size. However, when a lossy link is involved in a TCP connection, non-congestion random losses should also be considered. The congestion window size should not be decreased if a loss event is caused by link corruptions. To improve TCP performance over lossy links, in this paper, we first present that zero congestion loss could be achieved by appropriately setting the ECN marking threshold in the RED buffer. Secondly, we propose a new TCP algorithm, called Differentiation Capable TCP (Diff-C-TCP). Diff-C-TCP makes an assumption that packet losses are caused by link corruptions, and uses ECN (Explicit Congestion Notification) to determine any loss that may occasionally happen due to network congestion. We have shown that Diff-C-TCP performs very well in the presence of a lossy link.",
      "id": "402101"
    },
    {
      "title": "Comparing the performance of stochastic simulation on GPUs and OpenMP",
      "abstract": "Since stochastic computing performs operations using streams of bits that represent probability values instead of deterministic values, it can tolerate a large number of failures in a noisy system. However, the simulation of a stochastic implementation is extremely time-consuming. In this paper, we investigate two approaches to speed up the stochastic simulation: a GPU-based simulation and an OpenMP-based simulation. To compare these two approaches, we start with several basic stochastic computing elements SCEs and then use the stochastic implementation of a frame difference-based image segmentation algorithm as case study to conduct extensive experiments. Measured results show that the GPU-based simulation with 448 processing elements can achieve up to 119x performance speedup compared to the single-threaded CPU simulation and 17x performance speedup over the OpenMP-based simulation with eight processor cores. In addition, we present several performance optimisations for the GPU-based simulation which significantly benefit the performance of stochastic simulation.",
      "id": "402102"
    },
    {
      "title": "Tier-Code: An XOR-Based RAID-6 Code with Improved Write and Degraded-Mode Read Performance",
      "abstract": "The RAID-6 configuration is more tolerant of disk failures than other RAID levels because of its ability to tolerate two disk failures. However, previous RAID-6 codes suffer from two major overheads - the time of encoding or decoding processes plus the need to access multiple blocks when updating parities or recovering failed blocks. For example, the PS and Reed-Solomon codes do not have optimal computation complexity, while P-code, X-code and RDP-code must access multiple blocks to update parities during write operations. This work proposes a new XOR- based RAID-6 code, called Tier-code, which not only achieves the optimal parity computation complexity, but also increases the write and degraded-mode read performance compared to previous codes. It uses two tiers of coding, one at the block level and the other at the chunk level. Experimental results of software testing, simulation and ASIC synthesis for this new hierarchical code demonstrate that Tier-code can outperform the previous RAID-6 codes in both write performance and degraded-mode read performance while maintaining the optimal computation complexity in both hardware and software implementations.",
      "id": "402103"
    },
    {
      "title": "Dynamically Adapting To System Load And Program Behavior In Multiprogrammed Multiprocessor Systems",
      "abstract": "Parallel execution of application programs on a multiprocessor system may lead to performance degradation if the workload of a parallel region is not large enough to amortize the overheads associated with the parallel execution. Furthermore, if too many processes are running on the system in a multiprogrammed environment, the performance of the parallel application may degrade due to resource contention. This work proposes a comprehensive dynamic processor allocation scheme that takes both program behavior and system load into consideration when dynamically allocating processors. This mechanism was implemented on the Solaris operating system to dynamically control the execution of parallel C and Java application programs. Performance results show the effectiveness of this scheme in dynamically adapting to the current execution environment and program behavior, and that it outperforms a conventional time-shared system. Copyright (C) 2002 John Wiley Sons, Ltd.",
      "id": "402104"
    },
    {
      "title": "Circulating shared-registers for multiprocessor systems",
      "abstract": "The techniques for fine-grained data sharing are generally available only on specialized architectures, usually involving a shared-bus. The CIRculating Common-Update Sharing (CIRCUS) mechanism has low latency user-level contention-free access to a set of shared circulating data registers. The local access latency is near zero for both read and write operations. These operations can be mapped into more complex operations, such as arithmetic, logical, or data reduction operations such as minimum or sum to be performed by the circulating register hardware (CRH) on the circulating copy of a register. The CRH can also be used to perform atomic operations, such as fetch&add or swap. For a two-dimensional hierarchy of N processing elements (PEs), the write-latency (until the circulating register is updated with a new value) and the update-latency (when all CRH modules can see the updated value) have an optimum cluster size proportional to (N \u010b I/D)1/2, where I is the intercluster time and D is the inter-PE time, including the time between and through one node. The latencies, when optimally clustered, are proportional to (N \u010b I \u010b D)1/2. Sub-microsecond write-latency is expected for up to 15,255 PEs or 660 workstations. For higher levels of hierarchy, the expected write-latency is shown to be proportional to the sum of the latencies of all loop hierarchies. CIRCUS is applicable to a wide variety of system architectures and topologies.",
      "id": "402105"
    },
    {
      "title": "Self-Adjusting Scheduling: An On-Line Optimization Technique for Locality Management and Load Balancing",
      "abstract": "Techniques for scheduling parallel tasks on to the processors of a multiprocessor architecture must tradeoff three interrelated factors: 1) scheduling and synchronization costs, 2) load balancing, and 3) memory locality. Current scheduling techniques typically consider only one or two of these three factors at a time. We propose a novel Self- Adjusting Scheduling (SAS) algorithm that addresses all three factors simultaneously. This algorithm dedicates a single processor to execute an on-line branch-and-bound algorithm to search for partial schedules concurrent with the execution of tasks previously assigned to the remaining processors. This overlapped scheduling and execution, along with self-adjustment of duration of partial scheduling periods reduces scheduling and synchronization costs significantly. To satisfy the load-balancing and locality management, SAS introduces a unified cost model that accounts for both of these factors simultaneously. We compare the simulated performance of SAS with the Affinity Scheduling algorithm (AFS). The results of our experiments demonstrate that the potential loss of performance caused by dedicating a processor to scheduling is outweighed by the higher performance produced by SAS's dynamically adjusted schedules, even in systems with a small number of processors. SAS is a general on-line optimization technique that can be applied to a variety of dynamic scheduling problems.",
      "id": "402106"
    },
    {
      "title": "A Comprehensive Dynamic Processor Allocation Scheme for Multiprogrammed Multiprocessor Systems",
      "abstract": "Parallel execution of application programs on a multiprocessor system may lead to performance degradation if the workload of a parallel region is not large enough to amortize the overheads associated with the parallel execution. Furthermore, if too many processes are running on the system in a multiprogrammed environment, the performance of the parallel application may degrade due to resource contention. We propose a comprehensive dynamic processor allocation scheme that takes both program behavior and system load into consideration when dynamically allocating processors. We implemented this mechanism in the Java run-time system on Solaris to dynamically control the execution of parallel Java application programs. Performance results show the effectiveness of this scheme in dynamically adapting to the current execution environment and that it outperforms a conventional time-shared system.",
      "id": "402107"
    },
    {
      "title": "High performance solid state storage under Linux",
      "abstract": "Solid state drives (SSDs) allow single-drive performance that is far greater than disks can produce. Their low latency and potential for parallel operations mean that they are able to read and write data at speeds that strain operating system I/O interfaces. Additionally, their performance characteristics expose gaps in existing benchmarking methodologies. We discuss the impact on Linux system design of a prototype PCI Express SSD that operates at least an order of magnitude faster than most drives available today. We develop benchmarking strategies and focus on several areas where current Linux systems need improvement, and suggest methods of taking full advantage of such high-performance solid state storage. We demonstrate that an SSD can perform with high throughput, high operation rates, and low latency under the most difficult conditions. This suggests that high-performance SSDs can dramatically improve parallel I/O performance for future high performance computing (HPC) systems.",
      "id": "402108"
    },
    {
      "title": "Simulation of computer architectures: simulators, benchmarks, methodologies, and recommendations",
      "abstract": "Simulators have become an integral part of the computer architecture research and design process. Since they have the advantages of cost, time, and flexibility, architects use them to guide design space exploration and to quantify the efficacy of an enhancement. However, long simulation times and poor accuracy limit their effectiveness. To reduce the simulation time, architects have proposed several techniques that increase the simulation speed or throughput. To increase the accuracy, architects try to minimize the amount of error in their simulators and have proposed adding statistical rigor to their simulation methodology. Since a wide range of approaches exist and since many of them overlap, this paper describes, classifies, and compares them to aid the computer architect in selecting the most appropriate one.",
      "id": "402109"
    },
    {
      "title": "Dynamic Scheduling Techniques For Heterogeneous Computing Systems",
      "abstract": "There has been a recent increase of interest in heterogeneous computing systems, due partly to the fact that a single parallel architecture may not be adequate for exploiting all of a program's available parallelism. In some eases, heterogeneous systems have been shown to produce higher performance for lower cost than a single large machine. However, there has been only limited work on developing techniques and frameworks for partitioning and scheduling applications across the components of a heterogeneous system. In this paper we propose a general model for describing and evaluating heterogeneous systems that considers the degree of uniformity in the processing elements and the communication channels as a measure of the heterogeneity in the system. We also propose a class of dynamic scheduling algorithms for a heterogeneous computing system interconnected with an arbitrary communication network. These algorithms execute a novel optimization technique to dynamically compute schedules based on the potentially non-uniform computation and communication costs on the processors of a heterogeneous system. A unique aspect of these algorithms is that they easily adapt to different task granularities, to dynamically varying processor and system loads, and to systems with varying degrees of heterogeneity. Our simulations are designed to facilitate the evaluation of different scheduling algorithms under varying degrees of heterogeneity. The results show improved performance for our algorithms compared to the performance resulting from existing scheduling techniques.",
      "id": "402110"
    },
    {
      "title": "JavaSpMT: A Speculative Thread Pipelining Parallelization Model for Java Programs",
      "abstract": "This paper presents a new approach to improve performance of Java programs by extending the superthreaded speculative execution model to exploit coarse-grained parallelism on a shared-memory multiprocessor system. The parallelization model, called Java Speculative MultiThreading (JavaSpMT), combines control speculation with run-time dependence checking to parallelize a wide variety of loop constructs, including do-while loops, that cannot be parallelized using standard parallelization techniques. JavaSpMT is implemented using the standard Java multithreading mechanism and the parallelization is expressed using a Java source-to-source transformation. Thus, the transformed programs are still portable to any shared-memory multiprocessor system with a Java Virtual Machine implementation that supports native threads.",
      "id": "402111"
    },
    {
      "title": "Efficient Execution of Parallel Applications in Multiprogrammed Multiprocessor Systems",
      "abstract": "Existing techniques for sharing the processing resources in multiprogrammed shared-memory multiprocessors, such as time-sharing, space-sharing, and gang-scheduling, typically sacrifice the performance of individual parallel applications to improve overall system utilization. We present a new processor allocation technique that dynamically adjusts the number of processors an application is allowed to use for the execution of each parallel section of code based on the current system load. This approach exploits the maximum parallelism possible for each application without overloading the system. We implement our scheme on a Silicon Graphics Challenge multiprocessor system and evaluate its performance using applications from the Perfect Club benchmark suite and synthetic benchmarks. Our approach shows significant improvements over traditional time-sharing and gang scheduling. It has performance comparable to, or slightly better than, static space-sharing, but our strategy is more robust since, unlike static space-sharing, it does not require a priori knowledge of the applications' parallelism characteristics.",
      "id": "402112"
    },
    {
      "title": "Balancing Reuse Opportunities and Performance Gains with Subblock Value Reuse",
      "abstract": "The fact that instructions in programs often produce repetitive results has motivated researchers to explore various techniques, such as value prediction and value reuse, to exploit this behavior. Value prediction improves the available Instruction-Level Parallelism (ILP) in superscalar processors by allowing dependent instructions to be executed speculatively after predicting the values of their input operands. Value reuse, on the other hand, tries to eliminate redundant computation by storing the previously produced results of instructions and skipping the execution of redundant instructions. Previous value reuse mechanisms use a single instruction or a naturally formed instruction group, such as a basic block, a trace, or a function, as the reuse unit. These naturally-formed instruction groups are readily identifiable by the hardware at runtime without compiler assistance. However, the performance potential of a value reuse mechanism depends on its reuse detection time, the number of reuse opportunities, and the amount of work saved by skipping each reuse unit. Since larger instruction groups typically have fewer reuse opportunities than smaller groups, but they provide greater benefit for each reuse-detection process, it is very important to find the balance point that provides the largest overall performance gain. In this paper, we propose a new mechanism called subblock reuse. Subblocks are created by slicing basic blocks either dynamically or with compiler guidance. The dynamic approaches use the number of instructions, numbers of inputs and outputs, or the presence of store instructions to determine the subblock boundaries. The compiler-assisted approach slices basic blocks using data-flow considerations to balance the reuse granularity and the number of reuse opportunities. The results show that subblocks, which can produce up to 36 percent speedup if reused properly, are better candidates for reuse units than basic blocks. Although subblock reuse with compiler assistance has a substantial and consistent potential to improve the performance of superscalar processors, this scheme is not always the best performer. Subblocks restricted to two consecutive instructions demonstrate surprisingly good performance potential as well.",
      "id": "402113"
    },
    {
      "title": "Extending value reuse to basic blocks with compiler support",
      "abstract": "Speculative execution and instruction reuse are two important strategies that have been investigated for improving processor performance. Value prediction at the instruction level has been introduced to allow even more aggressive speculation and reuse than previous techniques. This study suggests that using compiler support to extend value reuse to a coarser granularity than a single instruction, such as a basic block, may have substantial performance benefits. We investigate the input and output values of basic blocks and find that these values can be quite regular and predictable. For the SPEC benchmark programs evaluated, 90 percent of the basic blocks have fewer than four register inputs, five live register outputs, four memory inputs, and two memory outputs. About 16 to 41 percent of all the basic blocks are simply repeating earlier calculations when the programs are compiled with the -O2 optimization level in the GCC compiler. Compiler optimizations, such as loop-unrolling and function inlining, affect the sizes of basic blocks, but have no significant or consistent impact on their value locality, nor the resulting performance. Based on these results, we evaluate the potential benefit of basic block reuse using a novel mechanism called the block history buffer. This mechanism records input and live output values of basic blocks to provide value reuse at the basic block level. Simulation results show that using a reasonably sized block history buffer to provide basic block reuse in a 4-way issue superscalar processor can improve execution time for the tested SPEC programs by 1 to 14 percent, with an overall average of 9 percent when using reasonable hardware assumptions",
      "id": "402114"
    },
    {
      "title": "Evaluating Benchmark Subsetting Approaches",
      "abstract": "To reduce the simulation time to a tractable amount or due to compilation (or other related) problems, computer architects often simulate only a subset of the benchmarks in a benchmark suite. However, if the architect chooses a subset of benchmarks that is not representative, the subsequent simulation results will, at best, be misleading or, at worst, yield incorrect conclusions. To address this problem, computer architects have recently proposed several statistically-based approaches to subset a benchmark suite. While some of these approaches are well-grounded statistically, what has not yet been thoroughly evaluated is the: 1) Absolute accuracy, 2) Relative accuracy across a range of processor and memory subsystem enhancements, and 3) Representativeness and coverage of each approach for a range of subset sizes. Specifically, this paper evaluates statistically-based subsetting approaches based on principal components analysis (PCA) and the Plackett and Burman (P&B) design, in addition to prevailing approaches such as integer vs. floating-point, core vs. memory-bound, by language, and at random. Our results show that the two statistically-based approaches, PCA and P&B, have the best absolute and relative accuracy for CRI and energy-delay product (EDP), produce subsets that are the most representative, and choose benchmark and input set pairs that are most well-distributed across the benchmark space. To achieve a 5% absolute CPI and EDP error, across a wide range of configurations, PCA and P&B typically need about 17 benchmark and input set pairs, while the other five approaches often choose more than 30 benchmark and input set pairs.",
      "id": "402115"
    },
    {
      "title": "An active data-aware cache consistency protocol for highly-scalable data-shipping DBMS architectures",
      "abstract": "In a data-shipping database system, data items are retrieved from the server machines, cached and processed at the client machines, and then shipped back to the server. Current cache consistency approaches typically rely on a centralized server or servers to enforce the necessary concurrency control actions. This centralized server imposes a limitation on the scalability and performance of these systems. This paper presents a new consistency protocol, Active Data-aware Cache Consistency (ADCC), that allows clients to be aware of the global state of their cached data via a two-tier directory. Using parallel communication with simultaneous client-server and client-client messages, ADCC reduces the network latency for detecting data conflicts by 50%, while increasing message overhead by about 8% only. In addition, ADCC improves scalability by partially offloading the concurrency control function from the server to the clients. An optimization, Lazy Update, is introduced to reduce the message overhead for maintaining client directory consistency. We implement ADCC in a page server DBMS architecture and compare it with the leading cache consistency algorithm, Callback Locking (CBL), which is the most widely implemented algorithm in commercial DBMSs. Our performance study shows that ADCC has a similar or lower abort rate, higher throughput, and better scalability for important workloads and system configurations. Both the simulation results and the analytic study indicate that the message overhead is low and that ADCC produces better behavior compared to the traditional server-based communication under high contention workloads.",
      "id": "402116"
    },
    {
      "title": "Power and Area Efficient Sorting Networks Using Unary Processing",
      "abstract": "Sorting is a common task in a wide range of applications from signal and image processing to switching systems. For applications that require high performance, sorting is often performed in hardware. Hardware cost and power consumption are the dominant concerns. The usual approach is to wire up a network of compare-and-swap units in a configuration called a Batcher (or Bitonic) network. This paper proposes a novel area-and power-efficient approach to sorting networks based on \"unary processing.\" Data is encoded as serial bit-streams, with values represented by the fraction of 1's in a stream of 0's and 1's. (This is an evolution of prior work on stochastic logic. Unlike stochastic logic, the unary approach is deterministic and completely accurate.) Synthesis results of complete sorting networks show up to 87% area and power saving compared to the conventional binary implementations. However, the latency increases. To mitigate the increased latency, the paper uses a novel time-encoding of data. The approach is validated with implementation of an important application of sorting: median filtering. The result is a low-cost, energy-efficient implementation of median filtering with only a slight accuracy loss.",
      "id": "402117"
    },
    {
      "title": "A hardware implementation of a radial basis function neural network using stochastic logic",
      "abstract": "Hardware implementations of artificial neural networks typically require significant amounts of hardware resources. This paper proposes a novel radial basis function artificial neural network using stochastic computing elements, which greatly reduces the required hardware. The Gaussian function used for the radial basis function is implemented with a two-dimensional finite state machine. The norm between the input data and the center point is optimized using simple logic gates. Results from two pattern recognition case studies, the standard Iris flower and the MICR font benchmarks, show that the difference of the average mean squared error between the proposed stochastic network and the corresponding traditional deterministic network is only 1.3% when the stochastic stream length is 10kbits. The accuracy of the recognition rate varies depending on the stream length, which gives the designer tremendous flexibility to tradeoff speed, power, and accuracy. From the FPGA implementation results, the hardware resource requirement of the proposed stochastic hidden neuron is only a few percent of the hardware requirement of the corresponding deterministic hidden neuron. The proposed stochastic network can be expanded to larger scale networks for complex tasks with simple hardware architectures.",
      "id": "402118"
    },
    {
      "title": "The synthesis of combinational logic to generate probabilities",
      "abstract": "As CMOS devices are scaled down into the nanometer regime, concerns about reliability are mounting. Instead of viewing nano-scale characteristics as an impediment, technologies such as PCMOS exploit them as a source of randomness. The technology generates random numbers that are used in probabilistic algorithms. With the PCMOS approach, different voltage levels are used to generate different probability values. If many different probability values are required, this approach becomes prohibitively expensive. In this work, we demonstrate a novel technique for synthesizing logic that generates new probabilities from a given set of probabilities. Three different scenarios are considered in terms of whether the given probabilities can be duplicated and whether there is freedom to choose them. In the case that the given probabilities cannot be duplicated and are predetermined, we provide a solution that is FPGA-mappable. In the case that the given probabilities cannot be duplicated but can be freely chosen, we provide an optimal choice. In the case that the given probabilities can be duplicated and can be freely chosen, we demonstrate how to generate arbitrary decimal probabilities from small sets -- a single probability or a pair of probabilities -- through combinational logic.",
      "id": "402119"
    },
    {
      "title": "PASS: A Hybrid Storage System for Performance-Synchronization Tradeoffs Using SSDs",
      "abstract": "Recent advances in flash memory show great potential to replace traditional hard drives (HDDs) with flash-based solid state drives (SSDs) from personal computing to distributed systems. However, it is still a long way to go before completely using SSDs for enterprise data storage. Considering the cost, performance, and reliability of SSDs, a practical solution is to combine both SSDs and HDDs together. This paper proposes a hybrid storage system named PASS (Performance-dAta Synchronization - hybrid storage System) to tradeoff between I/O performance and data discrepancy between SSDs and HDDs. PASS includes a high-performance SSD and a traditional HDD to store mirrored data for reliability. All of the I/O requests are redirected to the primary SSD first and then the updated data blocks are copied to the backup HDD asynchronously. In order to hide the latency of copying operations, we use an I/O window to coalesce write requests and maintain an ordered I/O queue to shorten the HDD seek and rotation times. Depending on the charateristics of different I/O workloads, we develop an adaptive policy to dynamically balance the foreground I/O processing and background mirroring. We implement a prototype system of PASS by developing a Linux device driver and conduct experiments on the IoMeter, PostMark, and TPCC benchmarks. Our results show that PASS can achieve up to 12 times the performance of a RAID1 storage system for the IoMeter and PostMark workloads while tolerating less than 2% data discrepancy between the primary SSD and the backup HDD. More interestingly, while PASS does not produce any performance benefit for the TPC-C benchmark, it does allow the system to scale to larger sizes than when using an HDD-based RAID system alone.",
      "id": "402120"
    },
    {
      "title": "Archer: A Community Distributed Computing Infrastructure for Computer Architecture Research and Education.",
      "abstract": "This paper introduces Archer, a community-based computing infrastructure supporting computer architecture research and education. The Archer system builds on virtualization techniques to provide a collaborative environment that facilitates sharing of computational resources and data among users. It integrates batch scheduling middleware to deliver high-throughput computing services aggregated from resources distributed across wide-area networks and owned by different participating entities in a seamless manner. The paper discusses the motivations that have led to the design of Archer, describes its core middleware components, and presents an analysis of the functionality and performance of the first wide-area deployment of Archer running a representative computer architecture simulation workload.",
      "id": "402121"
    },
    {
      "title": "Deterministic methods for stochastic computing using low-discrepancy sequences",
      "abstract": "Recently, deterministic approaches to stochastic computing (SC) have been proposed. These compute with the same constructs as stochastic computing but operate on deterministic bit streams. These approaches reduce the area, greatly reduce the latency (by an exponential factor), and produce completely accurate results. However, these methods do not scale well. Also, they lack the property of progressive precision enjoyed by SC. As a result, these deterministic approaches are not competitive for applications where some degree of inaccuracy can be tolerated. In this work we introduce two fast-converging, scalable deterministic approaches to SC based on low-discrepancy sequences. The results are completely accurate when running the operations for the required number of cycles. However, the computation can be truncated early if some inaccuracy is acceptable. Experimental results show that the proposed approaches significantly improve both the processing time and area-delay product compared to prior approaches.\n\n",
      "id": "402122"
    },
    {
      "title": "Exploring sub-block value reuse for superscalar processors",
      "abstract": "The performance potential of a value reuse mechanism depends on its reuse detection time, the number of reuse opportunities, and the amount of work saved by skipping each reuse unit. Since larger instruction groups typically have fewer reuse opportunities than smaller groups, but also provide greater benefit for each reuse-detection process, it is very important to find the balance point that provides the largest overall performance gain. We propose a new mechanism called sub-block reuse to balance the reuse granularity and the number of reuse opportunities. Our simulation results show that sub-block reuse with compiler assistance has a substantial and consistent potential to improve the performance of superscalar processors, with speedups ranging from 10% to 22%",
      "id": "402123"
    },
    {
      "title": "When Caches Aren't Enough: Data Prefetching Techniques",
      "abstract": "For the past few years, CPU performance has outpaced that of dynamic RAM, the primary component of main memory. Developers have had to use increasingly aggressive techniques to reduce or hide delays in accessing main memory. Even so, it is still not uncommon for scientific programs to spend more than half their runtimes stalled on memory requests. This poor performance is partially a result of the policies used to fetch data from main memory: Processors typically request data only when it is needed and then only if it is not first found in the cache. In contrast, data prefetching calls data into the cache before the processor needs it. Ideally, prefetching completes just in time for the processor to access the needed data. Prefetching can nearly double the performance of some scientific applications running on commercial systems. But to achieve this performance, it is critical that the most suitable prefetching technique is used. This article reviews three popular prefetching techniques and examines in which situations they are best used.",
      "id": "402124"
    },
    {
      "title": "Accelerating Lattice Boltzmann Fluid Flow Simulations Using Graphics Processors",
      "abstract": "Lattice Boltzmann Methods (LBM) are used for the computational simulation of Newtonian fluid dynamics. LBM-based simulations are readily parallelizable; they have been implemented on general-purpose processors, field-programmable gate arrays (FPGAs), and graphics processing units (GPUs). Of the three methods, the GPU implementations achieved the highest simulation performance per chip. With memory bandwidth of up to 141 GB/s and a theoretical maximum floating point performance of over 600 GFLOPS, CUDA-ready GPUs from NVIDIA provide an attractive platform for a wide range of scientific simulations, including LBM. This paper improves upon prior single-precision GPU LBM results for the D3Q19 model by increasing GPU multiprocessor occupancy, resulting in an increase in maximum performance by 20%, and by introducing a space-efficient storage method which reduces GPU RAM requirements by 50% at a slight detriment to performance. Both GPU implementations are over 28 times faster than a single-precision quad-core CPU version utilizing OpenMP.",
      "id": "402125"
    },
    {
      "title": "Scaling Analytical Models for Soft Error Rate Estimation Under a Multiple-Fault Environment",
      "abstract": "With continuing increase in soft error rates, its foreseeable that multiple faults will eventually need to be considered when modeling circuit sensitivity and evaluating faulttolerance techniques. Previous work that considers multiple faults assumes the faults are permanent. These assumptions aren't directly valid for soft errors. In this work, we evaluate two currently available models for analyzing circuit sensitivities but subject them to multiple transient fault environments. The first model targets the application of triple modular redundancy (TMR) to a non-branching (no fan-out) circuit with permanent faults. We demonstrate this model's inability to adequately predict sensitivity when circuits with branching are considered and subjected to transient faults. We motivate the need for a model that captures logical masking. This is provided by modifying a soft error rate (SER) estimation algorithm to handle multiple faults and gate input interdependence. We conclude that the simple non-branching model can predict a trade-off threshold for when TMR can benefit a circuit. However accurately predicting the magnitude of reliability changes requires the inclusion of more complicated branching effects and logical masking.",
      "id": "402126"
    }
  ]
